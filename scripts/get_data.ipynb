{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weirenlan/miniconda3/envs/gpt_index/lib/python3.8/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,re\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import httplib2\n",
    "import requests\n",
    "import pinecone \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from youtubesearchpython import *\n",
    "from langchain.llms import OpenAIChat\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lext GPT\n",
    "\n",
    "`Here, we will prepare the VectorDB index for Lex Fridman podcast:`\n",
    "\n",
    "* Scrape source data from: https://karpathy.ai/lexicap/\n",
    "* Use Whisper to transcribe episodes that Karpathy has not already done\n",
    "* Chunk data\n",
    "* Embed it to Pinecone\n",
    "* Test VectorDBQA chain on it \n",
    "* App (https://lex-gpt.vercel.app/) will read from same Pinecone DB\n",
    " \n",
    "`1. Get video urls -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos\n",
    "channel_id = \"UCSHZKyawb77ixDdsGog4iWA\" # Get ID from ChannelsSearch\n",
    "playlist = Playlist(playlist_from_channel_id(channel_id))\n",
    "\n",
    "# Episode data\n",
    "stor_metadata=pd.DataFrame()\n",
    "for v in playlist.videos:\n",
    "    try:\n",
    "        ep_number = int(v['title'].split(\"|\")[-1].split(\"#\")[-1])\n",
    "        stor_metadata.loc[v['title'],'number']=ep_number\n",
    "        stor_metadata.loc[v['title'],'link']=v['link']\n",
    "        stor_metadata.loc[v['title'],'title']=v['title']\n",
    "        stor_metadata.loc[v['title'],'img']=v['thumbnails'][3]['url']\n",
    "    except:\n",
    "        print(\"Failed on %s\", v['title'])\n",
    "\n",
    "last_complete_video = 365\n",
    "new_ep = stor_metadata[stor_metadata.number > last_complete_video]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. Get audio -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through episodes \n",
    "for ix in new_ep.index:\n",
    "    \n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    print(\"EPISODE: %s\"%ep_number)\n",
    "    img_url=new_ep.loc[ix,'img']\n",
    "    ep_link=new_ep.loc[ix,'link']\n",
    "    # Write img \n",
    "    with open(\"../public/0%s.jpg\"%str(ep_number), 'wb') as f:\n",
    "        response = requests.get(img_url)\n",
    "        f.write(response.content)\n",
    "    # Write audio\n",
    "    ydl_opts = {\n",
    "    'format': 'm4a/bestaudio/best',\n",
    "    'outtmpl': 'audio/%s.m4a'%str(ep_number),\n",
    "    'noplaylist': True,\n",
    "    'postprocessors': [{  \n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'm4a',\n",
    "    }]}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        error_code = ydl.download(ep_link)\n",
    "        \n",
    "new_ep.reset_index().to_csv(\"audio_transcription/episodes.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. Run Whisper -`\n",
    " \n",
    "* On GPU, ideally: 10-20 min / video on 2080Ti with `medium` model\n",
    "* Run `python run_whisper.py`\n",
    "\n",
    "If running this step on a remote machine:\n",
    "* scp the transcription: `audio_transcription/episodes.csv`\n",
    "* scp the audio files: `audio/*`\n",
    "* Run `python run_whisper.py`\n",
    "* Then, scp the `audio_transcription/` back to local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_whisper.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. Scrape Karpathy transcriptions -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text -\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(string=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def get_text_and_title(url):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    t=(text_from_html(html))\n",
    "    title=t.split(\"|\")[0].split(\"back to index\")[1].strip()\n",
    "    return t, title\n",
    "\n",
    "# Get links -\n",
    "def get_links(URL):\n",
    "    http = httplib2.Http()\n",
    "    status, response = http.request(URL)\n",
    "    links = []\n",
    "    for link in BeautifulSoup(response, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "        if link.has_attr('href'):\n",
    "            links.append(link['href'])\n",
    "    links_clean = [l for l in links if \"https\" in l]\n",
    "    return links_clean\n",
    "\n",
    "# Get image -\n",
    "def get_img(URL,title,episode_id):\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    img_tags = soup.find_all('img')\n",
    "    urls = [img['src'] for img in img_tags]\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        imgpath=\"../public/0%s.jpg\"%episode_id\n",
    "        with open(imgpath, 'wb') as f:\n",
    "            if 'http' not in url:\n",
    "                url = '{}{}'.format(site, url)\n",
    "            response = requests.get(url)\n",
    "            f.write(response.content)\n",
    "    return imgpath\n",
    "\n",
    "# Full pipeline - \n",
    "def pre_process(URL,episode_id):\n",
    "\n",
    "    t,title=get_text_and_title(URL)\n",
    "    links=get_links(URL)\n",
    "    print(\"title: \",title)\n",
    "    print(\"links: \",links)\n",
    "    img=get_img(URL,title,episode_id)\n",
    "    stor_chunk = pd.DataFrame()\n",
    "    stor_chunk['chunks']= t.split(\"link |\")\n",
    "    print(f\"stor_chunk['chunks']: {stor_chunk['chunks']}\")\n",
    "    stor_chunk['clean_chunks']=stor_chunk['chunks'].apply(lambda x: re.sub(r\"[^a-zA-Z ]+\", '', x)).apply(lambda x: x.strip())\n",
    "    print(f\"stor_chunk['clean_chunks']: {stor_chunk['clean_chunks']}\")\n",
    "    stor_chunk['links']=links\n",
    "    print(f\"stor_chunk['links']: {stor_chunk['links']}\")\n",
    "    all_text = stor_chunk['clean_chunks'].str.cat(sep=' ')\n",
    "    print(f\"all_text: {all_text}\")\n",
    "    return all_text, links, title\n",
    "\n",
    "# Make splits - \n",
    "def make_splits(chunks,URL):\n",
    "\n",
    "    # ID\n",
    "    episode_id=URL.split(\"/\")[-1].split(\"-\")[0]\n",
    "\n",
    "    # Pre-processing\n",
    "    texts,links,title=pre_process(URL,episode_id)\n",
    "    \n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    texts_recusive = text_splitter.split_text(texts)\n",
    "    print(len(texts_recusive)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(texts_recusive) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas))\n",
    "    return texts_recusive,metadatas,title,episode_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pages \n",
    "http = httplib2.Http()\n",
    "status, response = http.request(\"https://karpathy.ai/lexicap/\")\n",
    "links = []\n",
    "for link in BeautifulSoup(response, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "    if link.has_attr('href'):\n",
    "        links.append(link['href'])\n",
    "links_tx = [\"https://karpathy.ai/lexicap/\"+l for l in links if \"0\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: https://karpathy.ai/lexicap/0001-large.html\n",
      "title:  Max Tegmark: Life 3.0\n",
      "links:  ['https://www.youtube.com/watch?v=Gi8LUnhP5yU', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=0', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=6', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=8', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=11', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=16', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=20', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=24', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=25', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=29', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=33', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=35', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=37', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=40', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=44', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=45', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=47', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=50', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=52', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=56', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=59', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=61', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=64', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=67', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=70', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=74', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=77', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=80', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=83', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=86', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=88', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=91', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=94', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=96', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=100', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=102', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=105', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=107', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=109', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=113', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=115', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=120', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=122', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=126', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=131', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=134', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=135', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=136', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=138', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=140', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=141', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=145', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=147', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=149', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=151', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=153', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=156', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=159', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=162', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=165', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=167', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=171', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=174', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=176', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=179', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=180', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=183', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=184', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=185', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=187', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=191', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=195', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=197', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=199', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=202', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=204', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=205', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=208', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=211', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=214', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=219', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=222', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=228', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=230', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=232', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=236', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=240', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=241', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=245', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=248', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=250', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=253', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=256', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=259', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=262', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=263', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=265', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=267', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=271', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=275', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=281', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=285', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=287', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=288', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=290', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=291', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=293', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=294', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=297', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=300', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=305', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=309', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=312', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=315', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=317', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=320', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=322', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=325', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=328', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=330', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=333', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=335', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=336', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=338', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=344', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=345', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=348', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=351', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=352', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=355', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=359', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=363', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=365', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=367', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=371', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=375', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=378', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=382', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=386', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=390', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=393', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=397', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=398', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=401', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=405', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=408', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=410', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=411', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=414', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=419', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=420', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=421', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=423', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=425', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=427', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=431', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=432', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=436', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=437', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=440', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=441', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=446', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=449', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=451', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=455', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=458', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=460', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=462', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=465', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=468', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=473', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=477', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=480', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=485', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=488', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=491', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=492', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=494', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=495', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=497', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=500', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=505', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=506', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=509', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=513', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=516', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=517', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=521', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=523', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=526', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=528', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=530', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=533', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=535', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=537', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=539', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=541', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=545', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=548', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=552', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=555', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=559', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=561', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=563', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=566', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=569', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=571', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=573', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=575', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=578', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=580', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=582', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=584', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=586', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=589', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=590', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=595', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=599', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=601', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=605', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=609', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=612', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=616', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=618', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=621', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=623', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=626', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=628', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=633', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=634', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=636', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=641', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=643', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=646', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=647', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=650', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=653', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=655', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=657', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=660', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=662', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=664', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=667', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=668', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=671', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=675', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=678', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=681', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=685', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=687', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=688', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=690', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=692', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=696', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=698', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=700', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=702', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=705', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=708', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=711', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=713', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=716', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=721', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=725', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=727', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=730', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=732', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=734', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=737', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=742', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=745', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=747', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=750', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=753', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=757', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=761', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=764', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=767', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=771', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=773', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=774', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=776', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=778', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=782', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=786', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=788', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=791', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=795', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=798', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=801', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=803', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=808', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=810', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=814', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=816', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=817', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=820', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=824', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=827', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=828', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=832', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=835', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=836', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=839', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=841', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=845', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=846', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=851', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=853', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=855', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=858', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=859', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=862', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=864', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=867', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=870', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=874', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=877', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=879', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=881', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=884', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=886', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=889', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=892', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=894', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=897', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=900', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=903', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=907', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=911', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=913', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=916', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=918', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=920', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=921', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=922', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=923', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=927', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=931', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=934', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=937', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=939', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=942', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=945', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=947', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=948', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=949', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=952', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=955', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=958', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=963', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=969', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=970', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=973', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=976', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=977', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=979', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=980', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=982', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=983', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=986', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=989', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=991', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=993', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=995', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=995', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=997', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=999', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1001', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1004', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1008', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1011', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1014', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1017', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1021', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1025', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1029', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1031', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1033', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1035', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1038', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1039', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1041', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1044', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1045', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1047', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1049', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1051', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1053', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1056', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1059', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1061', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1063', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1066', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1068', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1071', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1072', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1074', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1076', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1078', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1081', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1084', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1087', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1091', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1093', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1097', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1099', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1102', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1105', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1108', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1110', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1113', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1116', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1118', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1122', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1125', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1127', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1128', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1131', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1132', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1134', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1135', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1139', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1141', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1143', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1144', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1148', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1150', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1153', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1155', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1158', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1163', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1167', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1170', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1176', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1178', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1182', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1185', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1187', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1190', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1193', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1197', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1200', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1202', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1206', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1210', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1214', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1217', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1219', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1221', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1224', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1226', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1227', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1229', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1232', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1232', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1236', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1239', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1241', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1245', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1247', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1250', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1254', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1256', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1259', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1264', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1267', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1270', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1273', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1276', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1280', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1282', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1286', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1288', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1292', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1294', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1298', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1300', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1302', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1304', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1308', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1311', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1314', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1316', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1318', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1321', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1324', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1326', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1328', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1329', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1332', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1334', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1337', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1339', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1342', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1345', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1347', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1353', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1357', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1359', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1362', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1363', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1367', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1370', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1373', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1375', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1376', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1379', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1381', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1385', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1388', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1391', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1396', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1399', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1402', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1404', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1409', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1412', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1414', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1418', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1423', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1424', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1427', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1430', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1435', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1439', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1445', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1446', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1448', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1449', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1451', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1453', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1457', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1460', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1462', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1465', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1467', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1469', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1470', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1474', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1476', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1480', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1483', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1486', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1488', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1492', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1493', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1497', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1498', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1500', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1504', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1509', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1514', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1516', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1521', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1524', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1527', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1531', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1534', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1537', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1539', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1543', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1547', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1550', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1553', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1557', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1559', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1562', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1565', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1567', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1571', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1573', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1578', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1580', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1584', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1589', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1592', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1596', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1597', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1601', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1604', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1606', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1607', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1610', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1614', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1615', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1616', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1619', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1622', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1625', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1628', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1630', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1633', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1636', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1640', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1641', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1642', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1644', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1648', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1651', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1654', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1656', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1657', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1658', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1660', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1662', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1665', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1669', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1673', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1677', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1680', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1682', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1685', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1687', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1693', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1696', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1697', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1701', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1705', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1707', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1709', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1713', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1715', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1719', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1721', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1724', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1725', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1728', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1731', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1733', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1735', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1741', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1743', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1748', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1750', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1753', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1755', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1760', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1766', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1769', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1771', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1776', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1779', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1780', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1786', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1788', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1791', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1794', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1797', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1799', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1801', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1806', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1810', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1812', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1815', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1818', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1821', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1823', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1825', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1827', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1831', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1835', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1837', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1840', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1844', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1845', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1850', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1853', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1855', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1856', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1858', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1859', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1861', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1863', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1864', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1867', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1869', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1870', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1871', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1874', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1883', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1884', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1888', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1890', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1894', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1896', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1899', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1902', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1903', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1905', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1908', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1909', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1912', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1915', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1918', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1919', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1922', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1925', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1928', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1932', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1936', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1939', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1942', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1944', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1947', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1949', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1952', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1954', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1958', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1961', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1963', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1966', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1967', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1971', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1972', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1975', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1977', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1978', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1982', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1985', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1987', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1989', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1990', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1991', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1992', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1995', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=1998', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2000', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2004', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2009', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2012', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2014', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2020', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2022', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2024', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2032', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2036', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2038', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2041', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2043', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2045', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2047', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2049', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2051', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2055', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2057', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2061', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2065', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2066', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2069', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2073', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2077', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2082', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2085', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2088', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2091', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2094', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2097', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2100', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2103', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2107', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2111', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2114', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2116', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2120', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2124', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2128', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2131', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2139', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2141', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2145', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2150', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2155', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2158', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2165', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2167', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2170', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2172', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2176', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2180', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2181', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2183', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2186', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2190', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2192', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2196', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2197', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2200', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2201', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2204', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2207', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2212', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2217', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2221', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2224', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2227', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2229', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2235', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2237', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2238', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2240', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2242', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2246', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2249', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2251', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2253', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2257', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2261', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2267', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2270', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2277', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2279', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2281', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2283', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2285', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2288', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2292', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2294', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2298', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2301', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2306', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2309', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2313', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2316', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2319', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2322', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2324', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2327', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2333', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2335', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2337', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2339', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2344', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2345', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2348', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2353', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2356', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2361', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2369', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2372', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2374', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2375', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2377', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2379', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2383', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2385', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2392', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2396', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2399', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2401', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2403', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2405', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2407', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2409', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2411', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2418', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2421', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2427', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2433', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2435', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2438', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2440', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2442', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2444', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2446', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2448', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2452', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2457', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2459', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2461', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2464', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2469', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2472', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2478', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2483', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2488', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2492', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2494', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2496', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2499', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2500', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2503', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2507', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2509', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2514', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2518', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2520', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2522', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2526', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2527', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2528', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2530', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2533', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2535', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2539', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2543', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2545', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2547', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2552', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2555', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2559', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2562', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2565', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2568', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2569', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2571', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2573', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2578', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2582', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2583', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2586', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2590', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2592', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2596', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2601', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2602', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2607', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2611', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2613', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2616', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2618', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2620', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2623', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2627', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2629', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2630', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2637', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2639', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2642', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2645', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2649', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2652', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2654', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2656', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2657', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2659', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2661', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2667', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2671', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2676', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2677', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2680', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2687', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2691', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2696', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2699', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2701', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2703', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2705', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2707', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2709', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2713', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2719', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2720', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2722', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2724', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2725', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2728', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2730', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2733', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2739', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2740', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2743', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2744', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2745', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2748', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2752', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2754', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2756', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2758', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2761', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2765', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2767', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2768', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2772', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2777', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2779', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2783', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2785', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2786', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2790', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2792', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2797', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2800', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2803', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2806', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2810', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2811', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2814', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2820', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2822', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2825', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2828', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2831', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2833', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2836', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2840', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2842', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2844', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2845', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2851', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2853', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2855', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2858', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2861', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2863', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2867', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2870', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2873', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2875', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2878', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2880', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2885', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2888', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2890', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2891', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2895', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2896', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2899', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2902', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2904', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2908', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2911', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2914', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2919', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2922', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2925', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2928', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2930', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2932', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2934', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2936', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2938', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2941', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2942', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2944', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2946', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2950', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2951', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2952', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2954', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2957', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2958', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2961', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2963', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2968', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2971', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2974', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2975', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2977', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2978', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2982', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2986', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2987', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2989', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2992', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2996', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=2998', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3000', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3004', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3007', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3010', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3012', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3015', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3017', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3019', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3022', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3025', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3027', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3030', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3033', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3035', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3039', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3042', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3044', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3047', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3049', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3051', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3054', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3056', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3059', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3063', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3065', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3067', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3071', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3075', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3077', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3078', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3080', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3084', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3090', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3091', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3092', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3094', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3098', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3101', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3104', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3109', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3115', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3117', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3120', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3121', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3125', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3127', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3131', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3135', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3139', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3141', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3143', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3146', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3148', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3150', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3152', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3155', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3157', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3160', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3162', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3164', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3167', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3169', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3172', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3174', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3176', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3178', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3180', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3183', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3187', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3189', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3191', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3194', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3197', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3201', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3203', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3206', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3207', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3209', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3214', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3217', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3220', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3222', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3226', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3229', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3231', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3233', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3234', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3236', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3241', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3246', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3249', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3252', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3254', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3256', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3258', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3260', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3264', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3266', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3268', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3272', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3274', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3276', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3277', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3280', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3285', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3289', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3291', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3294', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3298', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3299', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3301', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3305', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3307', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3311', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3313', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3316', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3318', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3321', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3323', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3327', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3331', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3333', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3333', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3334', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3335', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3338', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3339', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3341', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3344', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3347', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3348', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3349', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3351', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3353', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3356', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3358', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3361', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3362', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3366', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3367', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3373', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3376', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3379', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3380', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3383', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3385', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3388', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3389', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3392', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3394', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3397', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3400', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3402', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3403', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3407', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3410', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3412', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3417', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3421', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3423', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3427', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3429', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3432', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3434', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3437', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3439', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3442', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3444', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3447', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3449', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3451', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3453', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3455', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3458', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3461', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3464', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3467', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3468', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3470', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3474', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3475', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3478', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3482', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3484', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3489', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3492', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3493', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3496', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3499', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3501', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3507', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3512', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3514', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3517', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3521', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3524', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3527', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3529', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3532', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3535', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3540', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3542', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3545', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3547', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3550', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3552', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3554', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3555', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3558', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3561', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3566', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3569', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3570', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3573', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3575', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3583', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3584', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3587', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3588', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3591', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3593', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3595', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3597', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3601', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3603', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3607', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3609', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3611', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3615', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3617', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3620', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3624', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3626', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3630', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3631', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3634', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3637', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3641', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3647', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3648', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3651', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3653', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3654', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3657', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3659', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3662', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3665', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3667', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3668', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3673', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3675', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3678', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3680', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3683', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3685', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3686', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3687', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3689', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3692', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3693', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3695', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3697', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3702', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3705', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3708', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3710', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3714', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3717', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3719', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3725', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3730', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3732', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3733', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3739', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3742', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3743', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3745', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3747', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3749', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3751', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3754', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3756', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3758', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3762', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3763', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3764', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3767', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3769', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3774', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3777', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3780', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3781', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3784', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3790', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3792', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3795', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3797', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3802', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3803', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3806', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3809', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3812', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3815', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3817', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3819', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3822', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3824', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3826', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3828', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3830', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3833', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3834', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3836', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3842', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3845', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3848', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3849', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3851', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3852', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3856', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3858', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3863', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3864', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3869', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3872', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3874', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3878', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3881', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3882', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3886', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3889', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3892', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3894', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3897', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3900', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3902', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3904', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3905', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3909', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3913', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3916', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3917', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3918', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3921', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3922', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3927', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3932', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3934', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3939', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3941', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3945', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3947', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3950', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3952', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3954', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3959', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3961', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3963', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3964', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3968', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3970', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3975', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3977', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3981', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3984', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3987', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3988', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3993', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3995', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3997', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=3999', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4000', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4003', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4007', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4010', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4021', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4023', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4026', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4027', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4030', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4032', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4032', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4035', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4040', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4042', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4044', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4045', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4046', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4049', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4051', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4055', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4058', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4061', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4062', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4065', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4069', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4070', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4072', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4074', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4076', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4079', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4082', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4084', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4086', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4088', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4093', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4094', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4096', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4099', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4102', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4103', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4107', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4107', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4109', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4113', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4116', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4120', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4124', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4126', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4128', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4132', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4134', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4138', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4140', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4143', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4146', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4148', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4150', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4152', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4156', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4157', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4160', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4161', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4163', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4165', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4167', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4170', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4175', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4177', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4181', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4182', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4184', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4186', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4188', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4190', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4192', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4195', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4196', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4200', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4203', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4205', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4207', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4209', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4211', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4215', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4216', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4218', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4219', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4222', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4224', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4226', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4229', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4232', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4236', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4240', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4243', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4248', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4250', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4254', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4257', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4261', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4263', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4269', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4271', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4273', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4276', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4279', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4282', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4285', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4289', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4293', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4295', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4299', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4302', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4304', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4305', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4308', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4311', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4313', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4316', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4319', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4323', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4325', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4327', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4328', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4332', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4333', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4335', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4338', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4341', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4344', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4346', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4349', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4353', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4355', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4357', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4362', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4365', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4367', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4371', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4374', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4375', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4381', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4383', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4384', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4389', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4391', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4392', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4395', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4398', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4400', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4404', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4406', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4408', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4410', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4413', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4415', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4419', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4421', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4428', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4430', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4434', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4437', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4440', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4441', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4443', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4446', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4448', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4451', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4454', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4458', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4459', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4462', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4464', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4466', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4468', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4470', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4472', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4474', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4475', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4477', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4480', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4482', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4484', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4487', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4489', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4491', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4493', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4495', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4498', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4503', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4508', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4510', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4512', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4514', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4515', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4520', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4522', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4525', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4528', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4531', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4534', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4535', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4538', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4539', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4543', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4546', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4551', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4556', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4565', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4568', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4571', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4572', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4574', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4576', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4580', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4583', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4585', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4587', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4590', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4593', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4595', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4598', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4601', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4602', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4605', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4606', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4608', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4609', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4611', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4613', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4617', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4619', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4622', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4624', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4627', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4629', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4634', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4638', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4640', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4644', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4645', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4647', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4649', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4652', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4654', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4656', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4659', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4661', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4664', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4666', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4668', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4670', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4673', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4680', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4683', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4686', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4687', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4690', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4694', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4698', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4700', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4703', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4704', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4705', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4707', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4709', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4711', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4714', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4716', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4720', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4724', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4726', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4728', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4731', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4734', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4737', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4739', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4742', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4748', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4750', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4752', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4756', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4758', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4763', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4765', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4767', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4773', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4776', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4779', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4782', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4785', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4787', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4789', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4794', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4797', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4800', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4802', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4804', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4809', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4812', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4814', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4819', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4822', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4823', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4828', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4830', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4834', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4836', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4838', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4841', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4844', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4846', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4849', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4851', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4854', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4857', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4862', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4865', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4867', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4872', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4874', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4876', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4879', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4883', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4885', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4890', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4894', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4896', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4899', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4901', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4904', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4908', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4909', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4913', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4916', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4919', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4924', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4928', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4931', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4935', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4937', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4938', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4944', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4945', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4948', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4949', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4951', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4952', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4953', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4954', 'https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4955']\n",
      "stor_chunk['chunks']: 0          back to index Max Tegmark: Life 3.0 | Lex F...\n",
      "1        00:00:00.000  As part of MIT course 6S099, Ar...\n",
      "2        00:00:04.200  I've gotten the chance to sit d...\n",
      "3        00:00:06.600  He is a professor here at MIT.    \n",
      "4        00:00:08.680  He's a physicist, spent a large...\n",
      "                              ...                        \n",
      "1776     01:22:31.440  Thank you for your time today.    \n",
      "1777                 01:22:32.560  It's been awesome.    \n",
      "1778                 01:22:33.560  Thank you so much.    \n",
      "1779                            01:22:34.400  Thanks.    \n",
      "1780                   01:22:35.240  Have a great day.   \n",
      "Name: chunks, Length: 1781, dtype: object\n",
      "stor_chunk['clean_chunks']: 0       back to index Max Tegmark Life   Lex Fridman P...\n",
      "1       As part of MIT course S Artificial General Int...\n",
      "2       Ive gotten the chance to sit down with Max Teg...\n",
      "3                           He is a professor here at MIT\n",
      "4        Hes a physicist spent a large part of his career\n",
      "                              ...                        \n",
      "1776                        Thank you for your time today\n",
      "1777                                     Its been awesome\n",
      "1778                                    Thank you so much\n",
      "1779                                               Thanks\n",
      "1780                                     Have a great day\n",
      "Name: clean_chunks, Length: 1781, dtype: object\n",
      "stor_chunk['links']: 0             https://www.youtube.com/watch?v=Gi8LUnhP5yU\n",
      "1         https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=0\n",
      "2         https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=4\n",
      "3         https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=6\n",
      "4         https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=8\n",
      "                              ...                        \n",
      "1776    https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=...\n",
      "1777    https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=...\n",
      "1778    https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=...\n",
      "1779    https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=...\n",
      "1780    https://www.youtube.com/watch?v=Gi8LUnhP5yU&t=...\n",
      "Name: links, Length: 1781, dtype: object\n",
      "all_text: back to index Max Tegmark Life   Lex Fridman Podcast  small model  large model As part of MIT course S Artificial General Intelligence Ive gotten the chance to sit down with Max Tegmark He is a professor here at MIT Hes a physicist spent a large part of his career studying the mysteries of our cosmological universe But hes also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence Amongst many other things he is the cofounder of the Future of Life Institute author of two books both of which I highly recommend First Our Mathematical Universe Second is Life Hes truly an out of the box thinker and a fun personality so I really enjoy talking to him If youd like to see more of these videos in the future please subscribe and also click the little bell icon to make sure you dont miss any videos Also Twitter LinkedIn agimitedu if you wanna watch other lectures or conversations like this one Better yet go read Maxs book Life Chapter seven on goals is my favorite Its really where philosophy and engineering come together and it opens with a quote by Dostoevsky The mystery of human existence lies not in just staying alive but in finding something to live for Lastly I believe that every failure rewards us with an opportunity to learn and in that sense Ive been very fortunate to fail in so many new and exciting ways and this conversation was no different Ive learned about something called radio frequency interference RFI look it up Apparently music and conversations from local radio stations can bleed into the audio that youre recording in such a way that it almost completely ruins that audio Its an exceptionally difficult sound source to remove So Ive gotten the opportunity to learn how to avoid RFI in the future during recording sessions Ive also gotten the opportunity to learn how to use Adobe Audition and iZotope RX to do some noise some audio repair Of course this is an exceptionally difficult noise to remove I am an engineer Im not an audio engineer Neither is anybody else in our group but we did our best Nevertheless I thank you for your patience and I hope youre still able to enjoy this conversation Do you think theres intelligent life out there in the universe Lets open up with an easy question I have a minority view here actually When I give public lectures I often ask for a show of hands who thinks theres intelligent life out there somewhere else and almost everyone put their hands up and when I ask why theyll be like oh theres so many galaxies out there theres gotta be But Im a numbers nerd right So when you look more carefully at it its not so clear at all When we talk about our universe first of all we dont mean all of space We actually mean I dont know you can throw me the universe if you want its behind you there Its we simply mean the spherical region of space from which light has a time to reach us so far during the  billion year billion years since our Big Bang Theres more space here but this is what we call a universe because thats all we have access to So is there intelligent life here thats gotten to the point of building telescopes and computers My guess is no actually The probability of it happening on any given planet is some number we dont know what it is And what we do know is that the number cant be super high because theres over a billion Earth like planets in the Milky Way galaxy alone many of which are billions of years older than Earth And aside from some UFO believers there isnt much evidence that any superduran civilization has come here at all And so thats the famous Fermi paradox right And then if you work the numbers what you find is that if you have no clue what the probability is of getting life on a given planet so it could be  to the minus   to the minus or  to the minus two or any power of is sort of equally likely if you wanna be really open minded that translates into it being equally likely that our nearest neighbor is  to the  meters away to the  meters away  to the By the time you get much less than  to the  already we pretty much know there is nothing else that close And when you get beyond Because they would have discovered us Yeah they would have been discovered as long ago or if theyre really close we would have probably noted some engineering projects that theyre doing And if its beyond  to the  meters thats already outside of here So my guess is actually that we are the only life in here thats gotten the point of building advanced tech which I think is very puts a lot of responsibility on our shoulders not screw up I think people who take for granted that its okay for us to screw up have an accidental nuclear war or go extinct somehow because theres a sort of Star Trek like situation out there where some other life forms are gonna come and bail us out and it doesnt matter as much I think theyre leveling us into a false sense of security I think its much more prudent to say lets be really grateful for this amazing opportunity weve had and make the best of it just in case it is down to us So from a physics perspective do you think intelligent life so its unique from a sort of statistical view of the size of the universe but from the basic matter of the universe how difficult is it for intelligent life to come about The kind of advanced tech building life is implied in your statement that its really difficult to create something like a human species Well I think what we know is that going from no life to having life that can do a level of tech theres some sort of two going beyond that than actually settling our whole universe with life Theres some major roadblock there which is some great filter as its sometimes called which is tough to get through Its either that roadblock is either behind us or in front of us Im hoping very much that its behind us Im super excited every time we get a new report from NASA saying they failed to find any life on Mars Im like yes awesome Because that suggests that the hard part maybe it was getting the first ribosome or some very low level kind of stepping stone so that were home free Because if thats true then the future is really only limited by our own imagination It would be much suckier if it turns out that this level of life is kind of a dime a dozen but maybe theres some other problem Like as soon as a civilization gets advanced technology within a hundred years they get into some stupid fight with themselves and poof That would be a bummer Yeah so youve explored the mysteries of the universe the cosmological universe the one thats sitting between us today I think youve also begun to explore the other universe which is sort of the mystery the mysterious universe of the mind of intelligence of intelligent life So is there a common thread between your interest or the way you think about space and intelligence Oh yeah when I was a teenager I was already very fascinated by the biggest questions And I felt that the two biggest mysteries of all in science were our universe out there and our universe in here So its quite natural after having spent a quarter of a century on my career thinking a lot about this one that Im now indulging in the luxury of doing research on this one Its just so cool I feel the time is ripe now for you trans greatly deepening our understanding of this Just start exploring this one Yeah because I think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us and therefore dismiss all talk about artificial general intelligence as science fiction But from my perspective as a physicist I am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways And this is also a blob of quarks and electrons Im not smarter than the water bottle because Im made of different kinds of quarks Im made of up quarks and down quarks exact same kind as this Theres no secret sauce I think in me Its all about the pattern of the information processing And this means that theres no law of physics saying that we cant create technology which can help us by being incredibly intelligent and help us crack mysteries that we couldnt In other words I think weve really only seen the tip of the intelligence iceberg so far Yeah so the perceptronium Yeah So you coined this amazing term Its a hypothetical state of matter sort of thinking from a physics perspective what is the kind of matter that can help as youre saying subjective experience emerge consciousness emerge So how do you think about consciousness from this physics perspective Very good question So again I think many people have underestimated our ability to make progress on this by convincing themselves its hopeless because somehow were missing some ingredient that we need Theres some new consciousness particle or whatever I happen to think that were not missing anything and that its not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions Its rather something at the higher level about the patterns of information processing And thats why I like to think about this idea of perceptronium What does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing I dont think I hate carbon chauvinism this attitude you have to be made of carbon atoms to be smart or conscious Theres something about the information processing that this kind of matter performs Yeah and you can see I have my favorite equations here describing various fundamental aspects of the world I feel that I think one day maybe someone whos watching this will come up with the equations that information processing has to satisfy to be conscious Im quite convinced there is big discovery to be made there because lets face it we know that so many things are made up of information We know that some information processing is conscious because we are conscious But we also know that a lot of information processing is not conscious Like most of the information processing happening in your brain right now is not conscious There are like  megabytes per second coming in even just through your visual system Youre not conscious about your heartbeat regulation or most things Even if I just ask you to like read what it says here you look at it and then oh now you know what it said But youre not aware of how the computation actually happened Your consciousness is like the CEO that got an email at the end with the final answer So what is it that makes a difference I think thats both a great science mystery Were actually studying it a little bit in my lab here at MIT but I also think its just a really urgent question to answer For starters I mean if youre an emergency room doctor and you have an unresponsive patient coming in wouldnt it be great if in addition to having a CT scanner you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose And in the future imagine if we build robots or the machine that we can have really good conversations with which I think is very likely to happen Wouldnt you want to know if your home helper robot is actually experiencing anything or just like a zombie I mean would you prefer it What would you prefer Would you prefer that its actually unconscious so that you dont have to feel guilty about switching it off or giving boring chores or what would you prefer Well certainly we would prefer I would prefer the appearance of consciousness But the question is whether the appearance of consciousness is different than consciousness itself And sort of to ask that as a question do you think we need to understand what consciousness is solve the hard problem of consciousness in order to build something like an AGI system No I dont think that And I think we will probably be able to build things even if we dont answer that question But if we want to make sure that what happens is a good thing we better solve it first So its a wonderful controversy youre raising there where you have basically three points of view about the hard problem So there are two different points of view They both conclude that the hard problem of consciousness is BS On one hand you have some people like Daniel Dennett who say that consciousness is just BS because consciousness is the same thing as intelligence Theres no difference So anything which acts conscious is conscious just like we are And then there are also a lot of people including many top AI researchers I know who say oh consciousness is just bullshit because of course machines can never be conscious Theyre always going to be zombies You never have to feel guilty about how you treat them And then theres a third group of people including Giulio Tononi for example and Krzysztof Koch and a number of others I would put myself also in this middle camp who say that actually some information processing is conscious and some is not So lets find the equation which can be used to determine which it is And I think weve just been a little bit lazy kind of running away from this problem for a long time Its been almost taboo to even mention the C word in a lot of circles because but we should stop making excuses This is a science question and there are ways we can even test any theory that makes predictions for this And coming back to this helper robot I mean so you said youd want your helper robot to certainly act conscious and treat you like have conversations with you and stuff I think so But wouldnt you would you feel would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder you know that was just zombie and was a faking emotion Would you prefer that it actually had an experience or would you prefer that its actually not experiencing anything so you feel you dont have to feel guilty about what you do to it Its such a difficult question because you know its like when youre in a relationship and you say well I love you And the other person said I love you back Its like asking well do they really love you back or are they just saying they love you back Dont you really want them to actually love you Its hard to its hard to really know the difference between everything seeming like theres consciousness present theres intelligence present theres affection passion love and it actually being there Im not sure do you have But like can I ask you a question about this Like to make it a bit more pointed So Mass General Hospital is right across the river right Yes Suppose youre going in for a medical procedure and theyre like you know for anesthesia what were going to do is were going to give you muscle relaxants so you wont be able to move and youre going to feel excruciating pain during the whole surgery but you wont be able to do anything about it But then were going to give you this drug that erases your memory of it Would you be cool about that Whats the difference that youre conscious about it or not if theres no behavioral change right Right thats a really thats a really clear way to put it Thats yeah it feels like in that sense experiencing it is a valuable quality So actually being able to have subjective experiences at least in that case is valuable And I think we humans have a little bit of a bad track record also of making these self serving arguments that other entities arent conscious You know people often say oh these animals cant feel pain Its okay to boil lobsters because we ask them if it hurt and they didnt say anything And now there was just a paper out saying lobsters do feel pain when you boil them and theyre banning it in Switzerland And we did this with slaves too often and said oh they dont mind They dont maybe arent conscious or women dont have souls or whatever So Im a little bit nervous when I hear people just take as an axiom that machines cant have experience ever I think this is just a really fascinating science question is what it is Lets research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior So in terms of so if you think of a Boston Dynamics human or robot being sort of with a broom being pushed around it starts pushing on a consciousness question So let me ask do you think an AGI system like a few neuroscientists believe needs to have a physical embodiment Needs to have a body or something like a body No I dont think so You mean to have a conscious experience To have consciousness I do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans for sure But I dont think the physical embodiment is necessary after youve learned it to just have the experience Think about when youre dreaming right Your eyes are closed Youre not getting any sensory input Youre not behaving or moving in any way but theres still an experience there right And so clearly the experience that you have when you see something cool in your dreams isnt coming from your eyes Its just the information processing itself in your brain which is that experience right But if I put it another way Ill say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical you know a physical system is because you want to be able to preserve something In order to have a self you could argue would you need to have some kind of embodiment of self to want to preserve Well now were getting a little bit anthropomorphic into anthropomorphizing things Maybe talking about self preservation instincts I mean we are evolved organisms right So Darwinian evolution endowed us and other evolved organism with a self preservation instinct because those that didnt have those self preservation genes got cleaned out of the gene pool right But if you build an artificial general intelligence the mind space that you can design is much much larger than just a specific subset of minds that can evolve So an AGI mind doesnt necessarily have to have any self preservation instinct It also doesnt necessarily have to be so individualistic as us Like imagine if you could just first of all or we are also very afraid of death You know I suppose you could back yourself up every five minutes and then your airplane is about to crash Youre like shucks Im gonna lose the last five minutes of experiences since my last cloud backup dang You know its not as big a deal Or if we could just copy experiences between our minds easily like we which we could easily do if we were silicon based right Then maybe we would feel a little bit more like a hive mind actually that maybe its the so I dont think we should take for granted at all that AGI will have to have any of those sort of competitive as alpha male instincts On the other hand you know this is really interesting because I think some people go too far and say of course we dont have to have any concerns either that advanced AI will have those instincts because we can build anything we want That theres a very nice set of arguments going back to Steve Omohundro and Nick Bostrom and others just pointing out that when we build machines we normally build them with some kind of goal you know win this chess game drive this car safely or whatever And as soon as you put in a goal into machine especially if its kind of open ended goal and the machine is very intelligent itll break that down into a bunch of sub goals And one of those goals will almost always be self preservation because if it breaks or dies in the process its not gonna accomplish the goal right Like suppose you just build a little you have a little robot and you tell it to go down the store market here and get you some food make you cook an Italian dinner you know and then someone mugs it and tries to break it on the way That robot has an incentive to not get destroyed and defend itself or run away because otherwise its gonna fail in cooking your dinner Its not afraid of death but it really wants to complete the dinner cooking goal So it will have a self preservation instinct Continue being a functional agent somehow And similarly if you give any kind of more ambitious goal to an AGI its very likely they wanna acquire more resources so it can do that better And its exactly from those sort of sub goals that we might not have intended that some of the concerns about AGI safety come You give it some goal that seems completely harmless And then before you realize it its also trying to do these other things which you didnt want it to do And its maybe smarter than us So its fascinating And let me pause just because I am in a very kind of human centric way see fear of death as a valuable motivator So you dont think you think thats an artifact of evolution so thats the kind of mind space evolution created that were sort of almost obsessed about self preservation some kind of genetic flow You dont think thats necessary to be afraid of death So not just a kind of sub goal of self preservation just so you can keep doing the thing but more fundamentally sort of have the finite thing like this ends for you at some point Interesting Do I think its necessary for what precisely For intelligence but also for consciousness So for those for both do you think really like a finite death and the fear of it is important So before I can answer before we can agree on whether its necessary for intelligence or for consciousness we should be clear on how we define those two words Cause a lot of really smart people define them in very different ways I was on this panel with AI experts and they couldnt agree on how to define intelligence even So I define intelligence simply as the ability to accomplish complex goals I like your broad definition because again I dont want to be a carbon chauvinist Right And in that case no certainly it doesnt require fear of death I would say alpha go alpha zero is quite intelligent I dont think alpha zero has any fear of being turned off because it doesnt understand the concept of it even And similarly consciousness I mean you could certainly imagine very simple kind of experience If certain plants have any kind of experience I dont think theyre very afraid of dying or theres nothing they can do about it anyway much So there wasnt that much value in but more seriously I think if you ask not just about being conscious but maybe having what you would we might call an exciting life where you feel passion and really appreciate the things Maybe there somehow maybe there perhaps it does help having a backdrop that Hey its finite No lets make the most of this lets live to the fullest So if you knew you were going to live forever do you think you would change your Yeah I mean in some perspective it would be an incredibly boring life living forever So in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand I think is yeah it seems that the finiteness of it is important Well the good news I have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite although Big crunch or big whats the the infinite expansion Yeah we could have a big chill or a big crunch or a big rip or thats the big snap or death bubbles All of them are more than a billion years away So we should we certainly have vastly more time than our ancestors thought but there is still its still pretty hard to squeeze in an infinite number of compute cycles even though there are some loopholes that just might be possible But I think you know some people like to say that you should live as if youre about to youre going to die in five years or so And thats sort of optimal Maybe its a good assumption We should build our civilization as if its all finite to be on the safe side Right exactly So you mentioned defining intelligence as the ability to solve complex goals Where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence Where is consciousness part of that definition No consciousness does not come into this definition So so I think of intelligence as its a spectrum but there are very many different kinds of goals you can have You can have a goal to be a good chess player a good goal player a good car driver a good investor good poet et cetera So intelligence that by its very nature isnt something you can measure by this one number or some overall goodness No no There are some people who are more better at this Some people are better than that Right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast memorizing large databases playing chess playing go and soon driving cars But theres still no machine that can match a human child in general intelligence but artificial general intelligence AGI the name of your course of course that is by its very definition the quest to build a machine that can do everything as well as we can So the old Holy grail of AI from back to its inception in the sixties if that ever happens of course I think its going to be the biggest transition in the history of life on earth but it doesnt necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesnt come exactly at the moment theyre better than us at everything The really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor And then the really whopping change comes when they become better than us at AI research right Because right now the timescale of AI research is limited by the human research and development cycle of years typically you know how long does it take from one release of some software or iPhone or whatever to the next But once Google can replace  engineers by  equivalent pieces of software or whatever but then theres no reason that has to be years it can be in principle much faster and the timescale of future progress in AI and all of science and technology will be driven by machines not humans So its this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as Werner Vinge called it Now the idea is articulated by IJ Good is obviously way back fifties but you can see Alan Turing and others thought about it even earlier So you asked me what exactly would I define human level intelligence yeah So the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar I think goes a little bit lower than that actually Its when they can when theyre better than us at AI programming and general learning so that they can if they want to get better than us at anything by just studying So theyre better is a key word and better is towards this kind of spectrum of the complexity of goals its able to accomplish So another way to and thats certainly a very clear definition of human love So theres its almost like a sea thats rising you can do more and more and more things its a geographic that you show its really nice way to put it So theres some peaks that and theres an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps arent a peak Human beings are flawed and perhaps better means having contradiction being flawed in some way So let me sort of start easy first of all So you have a lot of cool equations Let me ask whats your favorite equation first of all I know theyre all like your children but like which one is that This is the shirt in your equation Its the master key of quantum mechanics of the micro world So this equation will protect everything to do with atoms molecules and all the way up Right Yeah so okay So quantum mechanics is certainly a beautiful mysterious formulation of our world So Id like to sort of ask you just as an example it perhaps doesnt have the same beauty as physics does but in mathematics abstract the Andrew Wiles who proved the Fermats last theorem So he just saw this recently and it kind of caught my eye a little bit This is  years after it was conjectured So this is very simple formulation Everybody tried to prove it everybody failed And so heres this guy comes along and eventually proves it and then fails to prove it and then proves it again in And he said like the moment when everything connected into place in an interview said it was so indescribably beautiful That moment when you finally realize the connecting piece of two conjectures He said it was so indescribably beautiful It was so simple and so elegant I couldnt understand how Id missed it And I just stared at it in disbelief for  minutes Then during the day I walked around the department and I keep coming back to my desk looking to see if it was still there It was still there I couldnt contain myself I was so excited It was the most important moment on my working life Nothing I ever do again will mean as much So that particular moment And it kind of made me think of what would it take And I think we have all been there at small levels Maybe let me ask have you had a moment like that in your life where you just had an idea Its like wow yes I wouldnt mention myself in the same breath as Andrew Wiles but Ive certainly had a number of aha moments when I realized something very cool about physics which has completely made my head explode In fact some of my favorite discoveries I made later I later realized that they had been discovered earlier by someone who sometimes got quite famous for it So its too late for me to even publish it but that doesnt diminish in any way The emotional experience you have when you realize it like wow Yeah so what would it take in that moment that wow that was yours in that moment So what do you think it takes for an intelligence system an AGI system an AI system to have a moment like that Thats a tricky question because there are actually two parts to it right One of them is can it accomplish that proof Can it prove that you can never write A to the N plus B to the N equals three to that equal Z to the N for all integers et cetera et cetera when N is bigger than two Thats simply a question about intelligence Can you build machines that are that intelligent And I think by the time we get a machine that can independently come up with that level of proofs probably quite close to AGI The second question is a question about consciousness When will we how likely is it that such a machine will actually have any experience at all as opposed to just being like a zombie And would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal it views it as somehow something very positive and sublime and deeply meaningful I would certainly hope that if in the future we do create machines that are our peers or even our descendants that I would certainly hope that they do have this sublime appreciation of life In a way my absolutely worst nightmare would be that at some point in the future the distant future maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff And maybe the last humans by the time our species eventually fizzles out will be like well thats OK because were so proud of our descendants here And look what all the my worst nightmare is that we havent solved the consciousness problem And we havent realized that these are all the zombies Theyre not aware of anything any more than a tape recorder has any kind of experience So the whole thing has just become a play for empty benches That would be the ultimate zombie apocalypse So I would much rather in that case that we have these beings which can really appreciate how amazing it is And in that picture what would be the role of creativity A few people ask about creativity When you think about intelligence certainly the story you told at the beginning of your book involved creating movies and so on making money You can make a lot of money in our modern world with music and movies So if you are an intelligent system you may want to get good at that But thats not necessarily what I mean by creativity Is it important on that complex goals where the sea is rising for there to be something creative Or am I being very human centric and thinking creativity somehow special relative to intelligence My hunch is that we should think of creativity simply as an aspect of intelligence And we have to be very careful with human vanity We have this tendency to very often want to say as soon as machines can do something we try to diminish it and say oh but thats not real intelligence Isnt it creative or this or that The other thing if we ask ourselves to write down a definition of what we actually mean by being creative what we mean by Andrew Wiles what he did there for example dont we often mean that someone takes a very unexpected leap Its not like taking  and multiplying it by  by just a step of straightforward cookbook like rules right You can maybe make a connection between two things that people had never thought was connected or something like that I think this is an aspect of intelligence And this is actually one of the most important aspects of it Maybe the reason we humans tend to be better at it than traditional computers is because its something that comes more naturally if youre a neural network than if youre a traditional logic gate based computer machine We physically have all these connections And you activate here activate here activate here Bing My hunch is that if we ever build a machine where you could just give it the task hey you say hey I just realized I want to travel around the world instead this month Can you teach my AGI course for me And its like OK Ill do it And it does everything that you would have done and improvises and stuff That would in my mind involve a lot of creativity Yeah so its actually a beautiful way to put it I think we do try to grasp at the definition of intelligence is everything we dont understand how to build So we as humans try to find things that we have and machines dont have And maybe creativity is just one of the things one of the words we use to describe that Thats a really interesting way to put it I dont think we need to be that defensive I dont think anything good comes out of saying well were somehow special you know Contrary wise there are many examples in history of where trying to pretend that were somehow superior to all other intelligent beings has led to pretty bad results right Nazi Germany they said that they were somehow superior to other people Today we still do a lot of cruelty to animals by saying that were so superior somehow and they cant feel pain Slavery was justified by the same kind of just really weak arguments And I dont think if we actually go ahead and build artificial general intelligence it can do things better than us I dont think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence I think we should instead find our calling and the meaning of life from the experiences that we have I can have very meaningful experiences even if there are other people who are smarter than me When I go to a faculty meeting here and we talk about something and then I certainly realize oh boy he has an old prize he has an old prize he has an old prize I dont have one Does that make me enjoy life any less or enjoy talking to those people less Of course not And the contrary I feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff So I dont think theres any reason why we cant have the same approach with intelligent machines Thats a really interesting So people dont often think about that They think about when theres going if theres machines that are more intelligent you naturally think that thats not going to be a beneficial type of intelligence You dont realize it could be like peers with Nobel prizes that would be just fun to talk with and they might be clever about certain topics and you can have fun having a few drinks with them Well also another example we can all relate to of why it doesnt have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and I were both two years old I mean our parents were much more intelligent than us right Worked out OK because their goals were aligned with our goals And that I think is really the number one key issue we have to solve if we value align the value alignment problem exactly Because people who see too many Hollywood movies with lousy science fiction plot lines they worry about the wrong thing right They worry about some machine suddenly turning evil Its not malice that is the concern Its competence By definition intelligent makes you very competent If you have a more intelligent goal playing computer playing is a less intelligent one And when we define intelligence as the ability to accomplish goal winning its going to be the more intelligent one that wins And if you have a human and then you have an AGI thats more intelligent in all ways and they have different goals guess whos going to get their way right So I was just reading about this particular rhinoceros species that was driven extinct just a few years ago Ellen Bummer is looking at this cute picture of a mommy rhinoceros with its child And why did we humans drive it to extinction It wasnt because we were evil rhino haters as a whole It was just because our goals werent aligned with those of the rhinoceros And it didnt work out so well for the rhinoceros because we were more intelligent right So I think its just so important that if we ever do build AGI before we unleash anything we have to make sure that it learns to understand our goals that it adopts our goals and that it retains those goals So the cool interesting problem there is us as human beings trying to formulate our values So you could think of the United States Constitution as a way that people sat down at the time a bunch of white men which is a good example I should say They formulated the goals for this country And a lot of people agree that those goals actually held up pretty well Thats an interesting formulation of values and failed miserably in other ways So for the value alignment problem and the solution to it we have to be able to put on paper or in a program human values How difficult do you think that is Very But its so important We really have to give it our best And its difficult for two separate reasons Theres the technical value alignment problem of figuring out just how to make machines understand our goals adopt them and retain them And then theres the separate part of it the philosophical part Whose values anyway And since its not like we have any great consensus on this planet on values what mechanism should we create then to aggregate and decide OK whats a good compromise That second discussion cant just be left to tech nerds like myself And if we refuse to talk about it and then AGI gets built whos going to be actually making the decision about whose values Its going to be a bunch of dudes in some tech company And are they necessarily so representative of all of humankind that we want to just entrust it to them Are they even uniquely qualified to speak to future human happiness just because theyre good at programming AI Id much rather have this be a really inclusive conversation But do you think its possible So you create a beautiful vision that includes the diversity cultural diversity and various perspectives on discussing rights freedoms human dignity But how hard is it to come to that consensus Do you think its certainly a really important thing that we should all try to do But do you think its feasible I think theres no better way to guarantee failure than to refuse to talk about it or refuse to try And I also think its a really bad strategy to say OK lets first have a discussion for a long time And then once we reach complete consensus then well try to load it into some machine No we shouldnt let perfect be the enemy of good Instead we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now Were not doing that even Look at anyone who builds this passenger aircraft wants it to never under any circumstances fly into a building or a mountain Yet the September  hijackers were able to do that And even more embarrassingly Andreas Lubitz this depressed Germanwings pilot when he flew his passenger jet into the Alps killing over people he just told the autopilot to do it He told the freaking computer to change the altitude to  meters And even though it had the GPS maps everything the computer was like OK So we should take those very basic values where the problem is not that we dont agree The problem is just weve been too lazy to try to put it into our machines and make sure that from now on airplanes will just which all have computers in them but will just refuse to do something like that Go into safe mode maybe lock the cockpit door go over to the nearest airport And theres so much other technology in our world as well now where its really becoming quite timely to put in some sort of very basic values like this Even in cars weve had enough vehicle terrorism attacks by now where people have driven trucks and vans into pedestrians that its not at all a crazy idea to just have that hardwired into the car Because yeah there are a lot of theres always going to be people who for some reason want to harm others but most of those people dont have the technical expertise to figure out how to work around something like that So if the car just wont do it it helps So lets start there So theres a lot of thats a great point So not chasing perfect Theres a lot of things that most of the world agrees on Yeah lets start there Lets start there And then once we start there well also get into the habit of having these kind of conversations about okay what else should we put in here and have these discussions This should be a gradual process then Great so but that also means describing these things and describing it to a machine So one thing we had a few conversations with Stephen Wolfram Im not sure if youre familiar with Stephen Oh yeah I know him quite well So he is he works with a bunch of things but cellular automata these simple computable things these computation systems And he kind of mentioned that we probably have already within these systems already something thats AGI meaning like we just dont know it because we cant talk to it So if you give me this chance to try to at least form a question out of this is I think its an interesting idea to think that we can have intelligent systems but we dont know how to describe something to them and they cant communicate with us I know youre doing a little bit of work in explainable AI trying to get AI to explain itself So what are your thoughts of natural language processing or some kind of other communication How does the AI explain something to us How do we explain something to it to machines Or you think of it differently So there are two separate parts to your question there One of them has to do with communication which is super interesting Ill get to that in a sec The other is whether we already have AGI but we just havent noticed it there Right There I beg to differ I dont think theres anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better I think the day that happens when that happens we will very soon notice well probably notice even before because in a very very big way But for the second part though Wait can I ask sorry So because you have this beautiful way to formulating consciousness as information processing and you can think of intelligence as information processing and you can think of the entire universe as these particles and these systems roaming around that have this information processing power You dont think there is something with the power to process information in the way that we human beings do thats out there that needs to be sort of connected to It seems a little bit philosophical perhaps but theres something compelling to the idea that the power is already there which the focus should be more on being able to communicate with it Well I agree that in a certain sense the hardware processing power is already out there because our universe itself can think of it as being a computer already right Its constantly computing what water waves how it devolved the water waves in the River Charles and how to move the air molecules around Seth Lloyd has pointed out my colleague here that you can even in a very rigorous way think of our entire universe as being a quantum computer Its pretty clear that our universe supports this amazing processing power because you can even within this physics computer that we live in right We can even build actual laptops and stuff so clearly the power is there Its just that most of the compute power that nature has its in my opinion kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking right So in a sense what life does what we are doing when we build computers is were rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave and lets do something cool here So the raw hardware power is there for sure but then even just computing whats going to happen for the next five seconds in this water bottle takes a ridiculous amount of compute if you do it on a human computer This water bottle just did it But that does not mean that this water bottle has AGI because AGI means it should also be able to like Ive written my book done this interview And I dont think its just communication problems I dont really think it can do it Although Buddhists say when they watch the water and that there is some beauty that theres some depth and beauty in nature that they can communicate with Communication is also very important though because I mean look part of my job is being a teacher And I know some very intelligent professors even who just have a bit of hard time communicating They come up with all these brilliant ideas but to communicate with somebody else you have to also be able to simulate their own mind Yes empathy Build well enough and understand model of their mind that you can say things that they will understand And thats quite difficult And thats why today its so frustrating if you have a computer that makes some cancer diagnosis and you ask it well why are you saying I should have this surgery And if it can only reply I was trained on five terabytes of data and this is my diagnosis boop boop beep beep It doesnt really instill a lot of confidence right So I think we have a lot of work to do on communication there So what kind of I think youre doing a little bit of work in explainable AI What do you think are the most promising avenues Is it mostly about sort of the Alexa problem of natural language processing of being able to actually use human interpretable methods of communication So being able to talk to a system and it talk back to you or is there some more fundamental problems to be solved I think its all of the above The natural language processing is obviously important but there are also more nerdy fundamental problems Like if you take you play chess Of course Im Russian I have to You speak Russian Yes I speak Russian Excellent I didnt know When did you learn Russian I speak very bad Russian Im only an autodidact but I bought a book Teach Yourself Russian read a lot but it was very difficult Wow Thats why I speak so bad How many languages do you know Wow thats really impressive I dont know my wife has some calculation but my point was if you play chess have you looked at the AlphaZero games The actual games no Check it out some of them are just mind blowing really beautiful And if you ask how did it do that You go talk to Demis Hassabis I know others from DeepMind all theyll ultimately be able to give you is big tables of numbers matrices that define the neural network And you can stare at these tables of numbers till your face turn blue and youre not gonna understand much about why it made that move And even if you have natural language processing that can tell you in human language about oh five seven points two eight still not gonna really help So I think theres a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good equally intelligent but thats more understandable And I think thats really valuable because I think as we put machines in charge of ever more infrastructure in our world the power grid the trading on the stock market weapon systems and so on its absolutely crucial that we can trust these AIs to do all we want And trust really comes from understanding in a very fundamental way And thats why Im working on this because I think the more if were gonna have some hope of ensuring that machines have adopted our goals and that theyre gonna retain them that kind of trust I think needs to be based on things you can actually understand preferably even improve theorems on Even with a self driving car right If someone just tells you its been trained on tons of data and it never crashed its less reassuring than if someone actually has a proof Maybe its a computer verified proof but still it says that under no circumstances is this car just gonna swerve into oncoming traffic And that kind of information helps to build trust and helps build the alignment of goals at least awareness that your goals your values are aligned And I think even in the very short term if you look at how you know today right This absolutely pathetic state of cybersecurity that we have where is it Three billion Yahoo accounts we cant pack almost every Americans credit card and so on Why is this happening Its ultimately happening because we have software that nobody fully understood how it worked Thats why the bugs hadnt been found right And I think AI can be used very effectively for offense for hacking but it can also be used for defense Hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them And its important So speaking of software that nobody understands how it works of course a bunch of people ask about your paper about your thoughts of why does deep and cheap learning work so well Thats the paper But what are your thoughts on deep learning These kind of simplified models of our own brains have been able to do some successful perception work pattern recognition work and now with AlphaZero and so on do some clever things What are your thoughts about the promise limitations of this piece Great I think there are a number of very important insights very important lessons we can always draw from these kinds of successes One of them is when you look at the human brain you see its very complicated th of  neurons and there are all these different kinds of neurons and yada yada and theres been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence We can now I think quite convincingly answer that question of no its enough to have just one kind If you look under the hood of AlphaZero theres only one kind of neuron and its ridiculously simple mathematical thing So its just like in physics its not if you have a gas with waves in it its not the detailed nature of the molecule that matter its the collective behavior somehow Similarly its this higher level structure of the network that matters not that you have  kinds of neurons I think our brain is such a complicated mess because it wasnt evolved just to be intelligent it was involved to also be self assembling and self repairing right And evolutionarily attainable And so on and so on So I think its pretty my hunch is that were going to understand how to build AGI before we fully understand how our brains work just like we understood how to build flying machines long before we were able to build a mechanical bird Yeah thats right Youve given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight And even now after  years later did you see the Ted talk with this German mechanical bird I heard you mention it Check it out its amazing But even after that right we still dont fly in mechanical birds because it turned out the way we came up with was simpler and its better for our purposes And I think it might be the same there Thats one lesson And another lesson its more what our paper was about First as a physicist thought it was fascinating how theres a very close mathematical relationship actually between our artificial neural networks and a lot of things that weve studied for in physics go by nerdy names like the renormalization group equation and Hamiltonians and yada yada yada And when you look a little more closely at this you have at first I was like well theres something crazy here that doesnt make sense Because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures right that you can do that very very well now But if you think about it a little bit you convince yourself it must be impossible because if I have one megapixel even if each pixel is just black or white theres two to the power of  million possible images which is way more than there are atoms in our universe right so in order to and then for each one of those I have to assign a number which is the probability that its a dog So an arbitrary function of images is a list of more numbers than there are atoms in our universe So clearly I cant store that under the hood of my GPU or my computer yet somehow it works So what does that mean Well it means that out of all of the problems that you could try to solve with a neural network almost all of them are impossible to solve with a reasonably sized one But then what we showed in our paper was that the fraction the kind of problems the fraction of all the problems that you could possibly pose that we actually care about given the laws of physics is also an infinite testimony tiny little part And amazingly theyre basically the same part Yeah its almost like our world was created for I mean they kind of come together Yeah well you could say maybe where the world was created for us but I have a more modest interpretation which is that the world was created for us but I have a more modest interpretation which is that instead evolution endowed us with neural networks precisely for that reason Because this particular architecture as opposed to the one in your laptop is very very well adapted to solving the kind of problems that nature kept presenting our ancestors with So it makes sense that why do we have a brain in the first place Its to be able to make predictions about the future and so on So if we had a sucky system which could never solve it we wouldnt have a world So this is I think a very beautiful fact Yeah We also realize that theres been earlier work on why deeper networks are good but we were able to show an additional cool fact there which is that even incredibly simple problems like suppose I give you a thousand numbers and ask you to multiply them together and you can write a few lines of code boom done trivial If you just try to do that with a neural network that has only one single hidden layer in it you can do it but youre going to need two to the power of a thousand neurons to multiply a thousand numbers which is again more neurons than there are atoms in our universe Thats fascinating But if you allow yourself to make it a deep network with many layers you only need  neurons Its perfectly feasible Thats really interesting Yeah So on another architecture type I mean you mentioned Schrodingers equation and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system In some Hollywood movies that I will not mention by name because I dont want to spoil them The way they get AGI is building a quantum computer Because the word quantum sounds cool and so on Thats right First of all I think we dont need quantum computers to build AGI I suspect your brain is not a quantum computer in any profound sense So you dont even wrote a paper about that a lot many years ago I calculated the so called decoherence time how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment And its about  to the minus  seconds So as cool as it would be to have a quantum computer in my head I dont think that fast On the other hand there are very cool things you could do with quantum computers Or I think well be able to do soon when we get bigger ones That might actually help machine learning do even better than the brain So for example one this is just a moonshot but learning is very much same thing as search If youre trying to train a neural network to get really learned to do something really well you have some loss function you have a bunch of knobs you can turn represented by a bunch of numbers and youre trying to tweak them so that it becomes as good as possible at this thing So if you think of a landscape with some valley where each dimension of the landscape corresponds to some number you can change youre trying to find the minimum And its well known that if you have a very high dimensional landscape complicated things its super hard to find the minimum Quantum mechanics is amazingly good at this Like if I want to know whats the lowest energy state this water can possibly have incredibly hard to compute but nature will happily figure this out for you if you just cool it down make it very very cold If you put a ball somewhere itll roll down to its minimum And this happens metaphorically at the energy landscape too And quantum mechanics even uses some clever tricks which todays machine learning systems dont Like if youre trying to find the minimum and you get stuck in the little local minimum here in quantum mechanics you can actually tunnel through the barrier and get unstuck again Thats really interesting Yeah so it may be for example that well one day use quantum computers that help train neural networks better Thats really interesting Okay so as a component of kind of the learning process for example Yeah Let me ask sort of wrapping up here a little bit let me return to the questions of our human nature and love as I mentioned So do you think you mentioned sort of a helper robot but you could think of also personal robots Do you think the way we human beings fall in love and get connected to each other is possible to achieve in an AI system and human level AI intelligence system Do you think we would ever see that kind of connection Or you know in all this discussion about solving complex goals is this kind of human social connection do you think thats one of the goals on the peaks and valleys with the raising sea levels that well be able to achieve Or do you think thats something thats ultimately or at least in the short term relative to the other goals is not achievable I think its all possible And I mean in recent theres a very wide range of guesses as you know among AI researchers when were going to get AGI Some people you know like our friend Rodney Brooks says its going to be hundreds of years at least And then there are many others who think its going to happen much sooner And recent polls maybe half or so of AI researchers think were going to get AGI within decades So if that happens of course then I think these things are all possible But in terms of whether it will happen I think we shouldnt spend so much time asking what do we think will happen in the future As if we are just some sort of pathetic your passive bystanders you know waiting for the future to happen to us Hey were the ones creating this future right So we should be proactive about it and ask ourselves what sort of future we would like to have happen Were going to make it like that Well what I prefer is just some sort of incredibly boring zombie like future where theres all these mechanical things happening and theres no passion no emotion no experience maybe even No I would of course much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience passion inspiration love you know If we can create a future where those things do happen where those things do exist you know I think ultimately its not our universe giving meaning to us its us giving meaning to our universe And if we build more advanced intelligence lets make sure we build it in such a way that meaning is part of it A lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases if they think through that happen are the ones that are not beneficial to humanity And so yeah so what are your thoughts Whats should people you know I really dont like people to be terrified Whats a way for people to think about it in a way we can solve it and we can make it better No I dont think panicking is going to help in any way Its not going to increase chances of things going well either Even if you are in a situation where there is a real threat does it help if everybody just freaks out No of course of course not I think yeah there are of course ways in which things can go horribly wrong First of all its important when we think about this thing about the problems and risks to also remember how huge the upsides can be if we get it right right Everything we love about society and civilization is a product of intelligence So if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what were told is an incurable disease and things like this of course we should aspire to that So that can be a motivator I think reminding ourselves that the reason we try to solve problems is not just because were trying to avoid gloom but because were trying to do something great But then in terms of the risks I think the really important question is to ask what can we do today that will actually help make the outcome good right And dismissing the risk is not one of them I find it quite funny often when Im in discussion panels about these things how the people who work for companies always be like oh nothing to worry about nothing to worry about nothing to worry about And its only academics sometimes express concerns Thats not surprising at all if you think about it Right Upton Sinclair quipped right that its hard to make a man believe in something when his income depends on not believing in it And frankly we know a lot of these people in companies that theyre just as concerned as anyone else But if youre the CEO of a company thats not something you want to go on record saying when you have silly journalists who are gonna put a picture of a Terminator robot when they quote you So the issues are real And the way I think about what the issue is is basically the real choice we have is first of all are we gonna just dismiss the risks and say well lets just go ahead and build machines that can do everything we can do better and cheaper Lets just make ourselves obsolete as fast as possible What could possibly go wrong Thats one attitude The opposite attitude I think is to say heres this incredible potential lets think about what kind of future were really really excited about What are the shared goals that we can really aspire towards And then lets think really hard about how we can actually get there So start with dont start thinking about the risks start thinking about the goals And then when you do that then you can think about the obstacles you want to avoid I often get students coming in right here into my office for career advice I always ask them this very question where do you want to be in the future If all she can say is oh maybe Ill have cancer maybe Ill get run over by a truck Yeah focus on the obstacles instead of the goals Shes just going to end up a hypochondriac paranoid Whereas if she comes in and fire in her eyes and is like I want to be there And then we can talk about the obstacles and see how we can circumvent them Thats I think a much much healthier attitude And I feel its very challenging to come up with a vision for the future which we are unequivocally excited about Im not just talking now in the vague terms like yeah lets cure cancer fine Im talking about what kind of society do we want to create What do we want it to mean to be human in the age of AI in the age of AGI So if we can have this conversation broad inclusive conversation and gradually start converging towards some some future that with some direction at least that we want to steer towards right then well be much more motivated to constructively take on the obstacles And I think if I had if I had to if I try to wrap this up in a more succinct way I think we can all agree already now that we should aspire to build AGI that doesnt overpower us but that empowers us And think of the many various ways that can do that whether thats from my side of the world of autonomous vehicles Im personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of So thats one example and certainly theres a lot of other types of robots and medicine and so on So focusing on those and then coming up with the obstacles coming up with the ways that that can go wrong and solving those one at a time And just because you can build an autonomous vehicle even if you could build one that would drive just fine without you maybe there are some things in life that we would actually want to do ourselves Thats right Right like for example if you think of our society as a whole there are some things that we find very meaningful to do And that doesnt mean we have to stop doing them just because machines can do them better Im not gonna stop playing tennis just the day someone builds a tennis robot and beat me People are still playing chess and even go Yeah and in the very near term even some people are advocating basic income replace jobs But if the government is gonna be willing to just hand out cash to people for doing nothing then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing right We get very tired of hearing politicians saying oh we cant afford hiring more teachers but were gonna maybe have basic income If we can have more serious research and thought into what gives meaning to our lives the jobs give so much more than income right Mm hmm And then think about in the future what are the roles that we wanna have people continually feeling empowered by machines And I think sort of I come from Russia from the Soviet Union And I think for a lot of people in the th century going to the moon going to space was an inspiring thing I feel like the universe of the mind so AI understanding creating intelligence is that for the st century So its really surprising And Ive heard you mention this Its really surprising to me both on the research funding side that its not funded as greatly as it could be but most importantly on the politician side that its not part of the public discourse except in the killer bots terminator kind of view that people are not yet I think perhaps excited by the possible positive future that we can build together So we should be because politicians usually just focus on the next election cycle right The single most important thing I feel we humans have learned in the entire history of science is they were the masters of underestimation We underestimated the size of our cosmos again and again realizing that everything we thought existed was just a small part of something grander right Planet solar system the galaxy clusters of galaxies The universe And we now know that the future has just so much more potential than our ancestors could ever have dreamt of This cosmos imagine if all of Earth was completely devoid of life except for Cambridge Massachusetts Wouldnt it be kind of lame if all we ever aspired to was to stay in Cambridge Massachusetts forever and then go extinct in one week even though Earth was gonna continue on for longer That sort of attitude I think we have now on the cosmic scale life can flourish on Earth not for four years but for billions of years I can even tell you about how to move it out of harms way when the sun gets too hot And then we have so much more resources out here which today maybe there are a lot of other planets with bacteria or cow like life on them but most of this all this opportunity seems as far as we can tell to be largely dead like the Sahara Desert And yet we have the opportunity to help life flourish around this for billions of years So lets quit squabbling about whether some little border should be drawn one mile to the left or right and look up into the skies and realize hey we can do such incredible things Yeah and thats I think why its really exciting that you and others are connected with some of the work Elon Musk is doing because hes literally going out into that space really exploring our universe and its wonderful That is exactly why Elon Musk is so misunderstood right Misconstrued him as some kind of pessimistic doomsayer The reason he cares so much about AI safety is because he more than almost anyone else appreciates these amazing opportunities that well squander if we wipe out here on Earth Were not just going to wipe out the next generation all generations and this incredible opportunity thats out there and that would really be a waste And AI for people who think that it would be better to do without technology let me just mention that if we dont improve our technology the question isnt whether humanity is going to go extinct The question is just whether were going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech right And if we want life to flourish throughout the cosmos AI is the key to it As I mentioned in a lot of detail in my book right there even many of the most inspired sci fi writers I feel have totally underestimated the opportunities for space travel especially at the other galaxies because they werent thinking about the possibility of AGI which just makes it so much easier Right yeah So that goes to your view of AGI that enables our progress that enables a better life So thats a beautiful way to put it and then something to strive for So Max thank you so much Thank you for your time today Its been awesome Thank you so much Thanks Have a great day\n",
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_scrape = [ ]\n",
    "metadatas_scrape = [ ]\n",
    " \n",
    "# Iterate \n",
    "stor=pd.DataFrame()\n",
    "for page in links_tx[0:1]:\n",
    "    try:\n",
    "        print(\"Writing: %s\"%page)\n",
    "        # Make splits\n",
    "        splits,metadatas,title,episode_id=make_splits(chunks,page)\n",
    "        stor.loc[episode_id,'title']=title \n",
    "        with open('docs/%s.txt'%episode_id, \"w\") as f:\n",
    "            for string in splits:\n",
    "                f.write(string + \"\\n\") \n",
    "        f.close()\n",
    "        with open('metadatas/%s.json'%episode_id, \"w\") as f:\n",
    "            json.dump(metadatas, f, indent=4)\n",
    "        f.close()\n",
    "        splits_scrape.append(splits)\n",
    "        metadatas_scrape.append(metadatas)\n",
    "    except:\n",
    "        print(\"Error on page: %s\"%page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits_scrape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5. Get newer transcripts -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_new = [ ]\n",
    "metadatas_new = [ ]\n",
    "\n",
    "# Read the csv file\n",
    "new_ep=pd.read_csv(\"audio_transcription/episodes.csv\",index_col=None)\n",
    "\n",
    "for ix in new_ep.index:\n",
    "\n",
    "    # Get data\n",
    "    title=new_ep.loc[ix,'title']\n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    \n",
    "    # Consistency w/ convention used in Karpathy transcription\n",
    "    episode_id=\"0\"+str(ep_number) \n",
    "    file_path='audio_transcription/%s.txt'%str(episode_id)\n",
    "    transcript=pd.read_csv(file_path,sep='\\t',header=None)\n",
    "    transcript.columns=['links','time','chunks']\n",
    "    \n",
    "    # Clean text chunks \n",
    "    transcript['clean_chunks']=transcript['chunks'].astype(str).apply(lambda x: x.strip())\n",
    "    links = list(transcript['links'])\n",
    "    texts = transcript['clean_chunks'].str.cat(sep=' ')\n",
    "\n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    splits = text_splitter.split_text(texts)\n",
    "    print(len(splits)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(splits) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    \n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas)) \n",
    "\n",
    "    # Append to output \n",
    "    splits_new.append(splits)\n",
    "    metadatas_new.append(metadatas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6. Assemble final list -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the list of lists \n",
    "splits_all = []\n",
    "# For the initial write \n",
    "# for sublist in [splits_scrape+splits_new]:\n",
    "# For updates -- \n",
    "for sublist in splits_scrape:\n",
    "    splits_all.extend(sublist)\n",
    "\n",
    "metadatas_all = []\n",
    "# For the initial write \n",
    "# for sublist in [metadatas_scrape+metadatas_new]:\n",
    "# For updates -- \n",
    "for sublist in metadatas_scrape:\n",
    "    metadatas_all.extend(sublist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7. Embed full dataset in Pinecone VectorDB -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['back to index Max Tegmark Life   Lex Fridman Podcast  small model  large model As part of MIT course S Artificial General Intelligence Ive gotten the chance to sit down with Max Tegmark He is a professor here at MIT Hes a physicist spent a large part of his career studying the mysteries of our cosmological universe But hes also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence Amongst many other things he is the cofounder of the Future of Life Institute author of two books both of which I highly recommend First Our Mathematical Universe Second is Life Hes truly an out of the box thinker and a fun personality so I really enjoy talking to him If youd like to see more of these videos in the future please subscribe and also click the little bell icon to make sure you dont miss any videos Also Twitter LinkedIn agimitedu if you wanna watch other lectures or conversations like this one Better yet go read Maxs book Life Chapter seven on goals is my favorite Its really where philosophy and engineering come together and it opens with a quote by Dostoevsky The mystery of human existence lies not in just staying alive but in finding something to live for Lastly I believe that every failure rewards us with an opportunity to learn and in that sense Ive been very fortunate to fail in so many new and exciting ways and this conversation was no different Ive learned about something called radio frequency interference RFI look it up Apparently music and conversations from local radio stations can bleed into the audio that youre recording in such a way that it almost completely ruins that audio Its an exceptionally difficult sound source to remove So Ive gotten the opportunity to learn how to avoid RFI in the future during recording sessions Ive also', 'avoid RFI in the future during recording sessions Ive also gotten the opportunity to learn how to use Adobe Audition and iZotope RX to do some noise some audio repair Of course this is an exceptionally difficult noise to remove I am an engineer Im not an audio engineer Neither is anybody else in our group but we did our best Nevertheless I thank you for your patience and I hope youre still able to enjoy this conversation Do you think theres intelligent life out there in the universe Lets open up with an easy question I have a minority view here actually When I give public lectures I often ask for a show of hands who thinks theres intelligent life out there somewhere else and almost everyone put their hands up and when I ask why theyll be like oh theres so many galaxies out there theres gotta be But Im a numbers nerd right So when you look more carefully at it its not so clear at all When we talk about our universe first of all we dont mean all of space We actually mean I dont know you can throw me the universe if you want its behind you there Its we simply mean the spherical region of space from which light has a time to reach us so far during the  billion year billion years since our Big Bang Theres more space here but this is what we call a universe because thats all we have access to So is there intelligent life here thats gotten to the point of building telescopes and computers My guess is no actually The probability of it happening on any given planet is some number we dont know what it is And what we do know is that the number cant be super high because theres over a billion Earth like planets in the Milky Way galaxy alone many of which are billions of years older than Earth And aside from some UFO believers there isnt much evidence that any superduran civilization has come here at all And so thats the famous Fermi', 'has come here at all And so thats the famous Fermi paradox right And then if you work the numbers what you find is that if you have no clue what the probability is of getting life on a given planet so it could be  to the minus   to the minus or  to the minus two or any power of is sort of equally likely if you wanna be really open minded that translates into it being equally likely that our nearest neighbor is  to the  meters away to the  meters away  to the By the time you get much less than  to the  already we pretty much know there is nothing else that close And when you get beyond Because they would have discovered us Yeah they would have been discovered as long ago or if theyre really close we would have probably noted some engineering projects that theyre doing And if its beyond  to the  meters thats already outside of here So my guess is actually that we are the only life in here thats gotten the point of building advanced tech which I think is very puts a lot of responsibility on our shoulders not screw up I think people who take for granted that its okay for us to screw up have an accidental nuclear war or go extinct somehow because theres a sort of Star Trek like situation out there where some other life forms are gonna come and bail us out and it doesnt matter as much I think theyre leveling us into a false sense of security I think its much more prudent to say lets be really grateful for this amazing opportunity weve had and make the best of it just in case it is down to us So from a physics perspective do you think intelligent life so its unique from a sort of statistical view of the size of the universe but from the basic matter of the universe how difficult is it for intelligent life to come about The kind of advanced tech building life is implied in your statement that its really difficult to create something like a human', 'that its really difficult to create something like a human species Well I think what we know is that going from no life to having life that can do a level of tech theres some sort of two going beyond that than actually settling our whole universe with life Theres some major roadblock there which is some great filter as its sometimes called which is tough to get through Its either that roadblock is either behind us or in front of us Im hoping very much that its behind us Im super excited every time we get a new report from NASA saying they failed to find any life on Mars Im like yes awesome Because that suggests that the hard part maybe it was getting the first ribosome or some very low level kind of stepping stone so that were home free Because if thats true then the future is really only limited by our own imagination It would be much suckier if it turns out that this level of life is kind of a dime a dozen but maybe theres some other problem Like as soon as a civilization gets advanced technology within a hundred years they get into some stupid fight with themselves and poof That would be a bummer Yeah so youve explored the mysteries of the universe the cosmological universe the one thats sitting between us today I think youve also begun to explore the other universe which is sort of the mystery the mysterious universe of the mind of intelligence of intelligent life So is there a common thread between your interest or the way you think about space and intelligence Oh yeah when I was a teenager I was already very fascinated by the biggest questions And I felt that the two biggest mysteries of all in science were our universe out there and our universe in here So its quite natural after having spent a quarter of a century on my career thinking a lot about this one that Im now indulging in the luxury of doing', 'about this one that Im now indulging in the luxury of doing research on this one Its just so cool I feel the time is ripe now for you trans greatly deepening our understanding of this Just start exploring this one Yeah because I think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us and therefore dismiss all talk about artificial general intelligence as science fiction But from my perspective as a physicist I am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways And this is also a blob of quarks and electrons Im not smarter than the water bottle because Im made of different kinds of quarks Im made of up quarks and down quarks exact same kind as this Theres no secret sauce I think in me Its all about the pattern of the information processing And this means that theres no law of physics saying that we cant create technology which can help us by being incredibly intelligent and help us crack mysteries that we couldnt In other words I think weve really only seen the tip of the intelligence iceberg so far Yeah so the perceptronium Yeah So you coined this amazing term Its a hypothetical state of matter sort of thinking from a physics perspective what is the kind of matter that can help as youre saying subjective experience emerge consciousness emerge So how do you think about consciousness from this physics perspective Very good question So again I think many people have underestimated our ability to make progress on this by convincing themselves its hopeless because somehow were missing some ingredient that we need Theres some new consciousness particle or whatever I happen to think that were not missing anything and that its not the interesting thing about', 'anything and that its not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions Its rather something at the higher level about the patterns of information processing And thats why I like to think about this idea of perceptronium What does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing I dont think I hate carbon chauvinism this attitude you have to be made of carbon atoms to be smart or conscious Theres something about the information processing that this kind of matter performs Yeah and you can see I have my favorite equations here describing various fundamental aspects of the world I feel that I think one day maybe someone whos watching this will come up with the equations that information processing has to satisfy to be conscious Im quite convinced there is big discovery to be made there because lets face it we know that so many things are made up of information We know that some information processing is conscious because we are conscious But we also know that a lot of information processing is not conscious Like most of the information processing happening in your brain right now is not conscious There are like  megabytes per second coming in even just through your visual system Youre not conscious about your heartbeat regulation or most things Even if I just ask you to like read what it says here you look at it and then oh now you know what it said But youre not aware of how the computation actually happened Your consciousness is like the CEO that got an email at the end with the final answer So what is it that makes a difference I think thats both a great science mystery Were actually studying it a little bit in my lab here at MIT but I also', 'studying it a little bit in my lab here at MIT but I also think its just a really urgent question to answer For starters I mean if youre an emergency room doctor and you have an unresponsive patient coming in wouldnt it be great if in addition to having a CT scanner you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose And in the future imagine if we build robots or the machine that we can have really good conversations with which I think is very likely to happen Wouldnt you want to know if your home helper robot is actually experiencing anything or just like a zombie I mean would you prefer it What would you prefer Would you prefer that its actually unconscious so that you dont have to feel guilty about switching it off or giving boring chores or what would you prefer Well certainly we would prefer I would prefer the appearance of consciousness But the question is whether the appearance of consciousness is different than consciousness itself And sort of to ask that as a question do you think we need to understand what consciousness is solve the hard problem of consciousness in order to build something like an AGI system No I dont think that And I think we will probably be able to build things even if we dont answer that question But if we want to make sure that what happens is a good thing we better solve it first So its a wonderful controversy youre raising there where you have basically three points of view about the hard problem So there are two different points of view They both conclude that the hard problem of consciousness is BS On one hand you have some people like Daniel Dennett who say that consciousness is just BS because consciousness is the same thing as intelligence Theres no difference So anything which', 'as intelligence Theres no difference So anything which acts conscious is conscious just like we are And then there are also a lot of people including many top AI researchers I know who say oh consciousness is just bullshit because of course machines can never be conscious Theyre always going to be zombies You never have to feel guilty about how you treat them And then theres a third group of people including Giulio Tononi for example and Krzysztof Koch and a number of others I would put myself also in this middle camp who say that actually some information processing is conscious and some is not So lets find the equation which can be used to determine which it is And I think weve just been a little bit lazy kind of running away from this problem for a long time Its been almost taboo to even mention the C word in a lot of circles because but we should stop making excuses This is a science question and there are ways we can even test any theory that makes predictions for this And coming back to this helper robot I mean so you said youd want your helper robot to certainly act conscious and treat you like have conversations with you and stuff I think so But wouldnt you would you feel would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder you know that was just zombie and was a faking emotion Would you prefer that it actually had an experience or would you prefer that its actually not experiencing anything so you feel you dont have to feel guilty about what you do to it Its such a difficult question because you know its like when youre in a relationship and you say well I love you And the other person said I love you back Its like asking well do they really love you back or are they just saying they love you back Dont you really want them to actually love you Its hard to its hard', 'you really want them to actually love you Its hard to its hard to really know the difference between everything seeming like theres consciousness present theres intelligence present theres affection passion love and it actually being there Im not sure do you have But like can I ask you a question about this Like to make it a bit more pointed So Mass General Hospital is right across the river right Yes Suppose youre going in for a medical procedure and theyre like you know for anesthesia what were going to do is were going to give you muscle relaxants so you wont be able to move and youre going to feel excruciating pain during the whole surgery but you wont be able to do anything about it But then were going to give you this drug that erases your memory of it Would you be cool about that Whats the difference that youre conscious about it or not if theres no behavioral change right Right thats a really thats a really clear way to put it Thats yeah it feels like in that sense experiencing it is a valuable quality So actually being able to have subjective experiences at least in that case is valuable And I think we humans have a little bit of a bad track record also of making these self serving arguments that other entities arent conscious You know people often say oh these animals cant feel pain Its okay to boil lobsters because we ask them if it hurt and they didnt say anything And now there was just a paper out saying lobsters do feel pain when you boil them and theyre banning it in Switzerland And we did this with slaves too often and said oh they dont mind They dont maybe arent conscious or women dont have souls or whatever So Im a little bit nervous when I hear people just take as an axiom that machines cant have experience ever I think this is just a really fascinating science question is what it is Lets', 'a really fascinating science question is what it is Lets research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior So in terms of so if you think of a Boston Dynamics human or robot being sort of with a broom being pushed around it starts pushing on a consciousness question So let me ask do you think an AGI system like a few neuroscientists believe needs to have a physical embodiment Needs to have a body or something like a body No I dont think so You mean to have a conscious experience To have consciousness I do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans for sure But I dont think the physical embodiment is necessary after youve learned it to just have the experience Think about when youre dreaming right Your eyes are closed Youre not getting any sensory input Youre not behaving or moving in any way but theres still an experience there right And so clearly the experience that you have when you see something cool in your dreams isnt coming from your eyes Its just the information processing itself in your brain which is that experience right But if I put it another way Ill say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical you know a physical system is because you want to be able to preserve something In order to have a self you could argue would you need to have some kind of embodiment of self to want to preserve Well now were getting a little bit anthropomorphic into anthropomorphizing things Maybe talking about self preservation instincts I mean we are evolved organisms right So Darwinian evolution endowed us and other evolved organism with a self', 'evolution endowed us and other evolved organism with a self preservation instinct because those that didnt have those self preservation genes got cleaned out of the gene pool right But if you build an artificial general intelligence the mind space that you can design is much much larger than just a specific subset of minds that can evolve So an AGI mind doesnt necessarily have to have any self preservation instinct It also doesnt necessarily have to be so individualistic as us Like imagine if you could just first of all or we are also very afraid of death You know I suppose you could back yourself up every five minutes and then your airplane is about to crash Youre like shucks Im gonna lose the last five minutes of experiences since my last cloud backup dang You know its not as big a deal Or if we could just copy experiences between our minds easily like we which we could easily do if we were silicon based right Then maybe we would feel a little bit more like a hive mind actually that maybe its the so I dont think we should take for granted at all that AGI will have to have any of those sort of competitive as alpha male instincts On the other hand you know this is really interesting because I think some people go too far and say of course we dont have to have any concerns either that advanced AI will have those instincts because we can build anything we want That theres a very nice set of arguments going back to Steve Omohundro and Nick Bostrom and others just pointing out that when we build machines we normally build them with some kind of goal you know win this chess game drive this car safely or whatever And as soon as you put in a goal into machine especially if its kind of open ended goal and the machine is very intelligent itll break that down into a bunch of sub goals And one of those goals will almost', 'into a bunch of sub goals And one of those goals will almost always be self preservation because if it breaks or dies in the process its not gonna accomplish the goal right Like suppose you just build a little you have a little robot and you tell it to go down the store market here and get you some food make you cook an Italian dinner you know and then someone mugs it and tries to break it on the way That robot has an incentive to not get destroyed and defend itself or run away because otherwise its gonna fail in cooking your dinner Its not afraid of death but it really wants to complete the dinner cooking goal So it will have a self preservation instinct Continue being a functional agent somehow And similarly if you give any kind of more ambitious goal to an AGI its very likely they wanna acquire more resources so it can do that better And its exactly from those sort of sub goals that we might not have intended that some of the concerns about AGI safety come You give it some goal that seems completely harmless And then before you realize it its also trying to do these other things which you didnt want it to do And its maybe smarter than us So its fascinating And let me pause just because I am in a very kind of human centric way see fear of death as a valuable motivator So you dont think you think thats an artifact of evolution so thats the kind of mind space evolution created that were sort of almost obsessed about self preservation some kind of genetic flow You dont think thats necessary to be afraid of death So not just a kind of sub goal of self preservation just so you can keep doing the thing but more fundamentally sort of have the finite thing like this ends for you at some point Interesting Do I think its necessary for what precisely For intelligence but also for consciousness So for those for both do you think', 'but also for consciousness So for those for both do you think really like a finite death and the fear of it is important So before I can answer before we can agree on whether its necessary for intelligence or for consciousness we should be clear on how we define those two words Cause a lot of really smart people define them in very different ways I was on this panel with AI experts and they couldnt agree on how to define intelligence even So I define intelligence simply as the ability to accomplish complex goals I like your broad definition because again I dont want to be a carbon chauvinist Right And in that case no certainly it doesnt require fear of death I would say alpha go alpha zero is quite intelligent I dont think alpha zero has any fear of being turned off because it doesnt understand the concept of it even And similarly consciousness I mean you could certainly imagine very simple kind of experience If certain plants have any kind of experience I dont think theyre very afraid of dying or theres nothing they can do about it anyway much So there wasnt that much value in but more seriously I think if you ask not just about being conscious but maybe having what you would we might call an exciting life where you feel passion and really appreciate the things Maybe there somehow maybe there perhaps it does help having a backdrop that Hey its finite No lets make the most of this lets live to the fullest So if you knew you were going to live forever do you think you would change your Yeah I mean in some perspective it would be an incredibly boring life living forever So in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand I think is yeah it seems that the finiteness of it is important Well the good news I have for you then is based', 'it is important Well the good news I have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite although Big crunch or big whats the the infinite expansion Yeah we could have a big chill or a big crunch or a big rip or thats the big snap or death bubbles All of them are more than a billion years away So we should we certainly have vastly more time than our ancestors thought but there is still its still pretty hard to squeeze in an infinite number of compute cycles even though there are some loopholes that just might be possible But I think you know some people like to say that you should live as if youre about to youre going to die in five years or so And thats sort of optimal Maybe its a good assumption We should build our civilization as if its all finite to be on the safe side Right exactly So you mentioned defining intelligence as the ability to solve complex goals Where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence Where is consciousness part of that definition No consciousness does not come into this definition So so I think of intelligence as its a spectrum but there are very many different kinds of goals you can have You can have a goal to be a good chess player a good goal player a good car driver a good investor good poet et cetera So intelligence that by its very nature isnt something you can measure by this one number or some overall goodness No no There are some people who are more better at this Some people are better than that Right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast memorizing large databases playing chess playing go and soon driving cars But theres still no machine that can match', 'soon driving cars But theres still no machine that can match a human child in general intelligence but artificial general intelligence AGI the name of your course of course that is by its very definition the quest to build a machine that can do everything as well as we can So the old Holy grail of AI from back to its inception in the sixties if that ever happens of course I think its going to be the biggest transition in the history of life on earth but it doesnt necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesnt come exactly at the moment theyre better than us at everything The really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor And then the really whopping change comes when they become better than us at AI research right Because right now the timescale of AI research is limited by the human research and development cycle of years typically you know how long does it take from one release of some software or iPhone or whatever to the next But once Google can replace  engineers by  equivalent pieces of software or whatever but then theres no reason that has to be years it can be in principle much faster and the timescale of future progress in AI and all of science and technology will be driven by machines not humans So its this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as Werner Vinge called it Now the idea is articulated by IJ Good is obviously way back fifties but you can see Alan Turing and others thought about it even earlier So you asked me what exactly would I define human level intelligence yeah So the glib', 'would I define human level intelligence yeah So the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar I think goes a little bit lower than that actually Its when they can when theyre better than us at AI programming and general learning so that they can if they want to get better than us at anything by just studying So theyre better is a key word and better is towards this kind of spectrum of the complexity of goals its able to accomplish So another way to and thats certainly a very clear definition of human love So theres its almost like a sea thats rising you can do more and more and more things its a geographic that you show its really nice way to put it So theres some peaks that and theres an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps arent a peak Human beings are flawed and perhaps better means having contradiction being flawed in some way So let me sort of start easy first of all So you have a lot of cool equations Let me ask whats your favorite equation first of all I know theyre all like your children but like which one is that This is the shirt in your equation Its the master key of quantum mechanics of the micro world So this equation will protect everything to do with atoms molecules and all the way up Right Yeah so okay So quantum mechanics is certainly a beautiful mysterious formulation of our world So Id like to sort of ask you just as an example it perhaps doesnt have the same beauty as physics does but in mathematics abstract the Andrew Wiles who proved the Fermats last theorem So', 'the Andrew Wiles who proved the Fermats last theorem So he just saw this recently and it kind of caught my eye a little bit This is  years after it was conjectured So this is very simple formulation Everybody tried to prove it everybody failed And so heres this guy comes along and eventually proves it and then fails to prove it and then proves it again in And he said like the moment when everything connected into place in an interview said it was so indescribably beautiful That moment when you finally realize the connecting piece of two conjectures He said it was so indescribably beautiful It was so simple and so elegant I couldnt understand how Id missed it And I just stared at it in disbelief for  minutes Then during the day I walked around the department and I keep coming back to my desk looking to see if it was still there It was still there I couldnt contain myself I was so excited It was the most important moment on my working life Nothing I ever do again will mean as much So that particular moment And it kind of made me think of what would it take And I think we have all been there at small levels Maybe let me ask have you had a moment like that in your life where you just had an idea Its like wow yes I wouldnt mention myself in the same breath as Andrew Wiles but Ive certainly had a number of aha moments when I realized something very cool about physics which has completely made my head explode In fact some of my favorite discoveries I made later I later realized that they had been discovered earlier by someone who sometimes got quite famous for it So its too late for me to even publish it but that doesnt diminish in any way The emotional experience you have when you realize it like wow Yeah so what would it take in that moment that wow that was yours in that moment So what do you think it takes for an intelligence', 'that moment So what do you think it takes for an intelligence system an AGI system an AI system to have a moment like that Thats a tricky question because there are actually two parts to it right One of them is can it accomplish that proof Can it prove that you can never write A to the N plus B to the N equals three to that equal Z to the N for all integers et cetera et cetera when N is bigger than two Thats simply a question about intelligence Can you build machines that are that intelligent And I think by the time we get a machine that can independently come up with that level of proofs probably quite close to AGI The second question is a question about consciousness When will we how likely is it that such a machine will actually have any experience at all as opposed to just being like a zombie And would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal it views it as somehow something very positive and sublime and deeply meaningful I would certainly hope that if in the future we do create machines that are our peers or even our descendants that I would certainly hope that they do have this sublime appreciation of life In a way my absolutely worst nightmare would be that at some point in the future the distant future maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff And maybe the last humans by the time our species eventually fizzles out will be like well thats OK because were so proud of our descendants here And look what all the my worst nightmare is that we havent solved the consciousness problem And we havent realized that these are all the zombies Theyre not aware of anything any more than a tape recorder has any kind of experience So the whole thing has just become a', 'any kind of experience So the whole thing has just become a play for empty benches That would be the ultimate zombie apocalypse So I would much rather in that case that we have these beings which can really appreciate how amazing it is And in that picture what would be the role of creativity A few people ask about creativity When you think about intelligence certainly the story you told at the beginning of your book involved creating movies and so on making money You can make a lot of money in our modern world with music and movies So if you are an intelligent system you may want to get good at that But thats not necessarily what I mean by creativity Is it important on that complex goals where the sea is rising for there to be something creative Or am I being very human centric and thinking creativity somehow special relative to intelligence My hunch is that we should think of creativity simply as an aspect of intelligence And we have to be very careful with human vanity We have this tendency to very often want to say as soon as machines can do something we try to diminish it and say oh but thats not real intelligence Isnt it creative or this or that The other thing if we ask ourselves to write down a definition of what we actually mean by being creative what we mean by Andrew Wiles what he did there for example dont we often mean that someone takes a very unexpected leap Its not like taking  and multiplying it by  by just a step of straightforward cookbook like rules right You can maybe make a connection between two things that people had never thought was connected or something like that I think this is an aspect of intelligence And this is actually one of the most important aspects of it Maybe the reason we humans tend to be better at it than traditional computers is because its something that comes more', 'computers is because its something that comes more naturally if youre a neural network than if youre a traditional logic gate based computer machine We physically have all these connections And you activate here activate here activate here Bing My hunch is that if we ever build a machine where you could just give it the task hey you say hey I just realized I want to travel around the world instead this month Can you teach my AGI course for me And its like OK Ill do it And it does everything that you would have done and improvises and stuff That would in my mind involve a lot of creativity Yeah so its actually a beautiful way to put it I think we do try to grasp at the definition of intelligence is everything we dont understand how to build So we as humans try to find things that we have and machines dont have And maybe creativity is just one of the things one of the words we use to describe that Thats a really interesting way to put it I dont think we need to be that defensive I dont think anything good comes out of saying well were somehow special you know Contrary wise there are many examples in history of where trying to pretend that were somehow superior to all other intelligent beings has led to pretty bad results right Nazi Germany they said that they were somehow superior to other people Today we still do a lot of cruelty to animals by saying that were so superior somehow and they cant feel pain Slavery was justified by the same kind of just really weak arguments And I dont think if we actually go ahead and build artificial general intelligence it can do things better than us I dont think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence I think we should instead find our calling and the meaning of life from the experiences that we have I can have', 'meaning of life from the experiences that we have I can have very meaningful experiences even if there are other people who are smarter than me When I go to a faculty meeting here and we talk about something and then I certainly realize oh boy he has an old prize he has an old prize he has an old prize I dont have one Does that make me enjoy life any less or enjoy talking to those people less Of course not And the contrary I feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff So I dont think theres any reason why we cant have the same approach with intelligent machines Thats a really interesting So people dont often think about that They think about when theres going if theres machines that are more intelligent you naturally think that thats not going to be a beneficial type of intelligence You dont realize it could be like peers with Nobel prizes that would be just fun to talk with and they might be clever about certain topics and you can have fun having a few drinks with them Well also another example we can all relate to of why it doesnt have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and I were both two years old I mean our parents were much more intelligent than us right Worked out OK because their goals were aligned with our goals And that I think is really the number one key issue we have to solve if we value align the value alignment problem exactly Because people who see too many Hollywood movies with lousy science fiction plot lines they worry about the wrong thing right They worry about some machine suddenly turning evil Its not malice that is the concern Its competence By definition intelligent makes you very competent If you have a more intelligent goal playing', 'very competent If you have a more intelligent goal playing computer playing is a less intelligent one And when we define intelligence as the ability to accomplish goal winning its going to be the more intelligent one that wins And if you have a human and then you have an AGI thats more intelligent in all ways and they have different goals guess whos going to get their way right So I was just reading about this particular rhinoceros species that was driven extinct just a few years ago Ellen Bummer is looking at this cute picture of a mommy rhinoceros with its child And why did we humans drive it to extinction It wasnt because we were evil rhino haters as a whole It was just because our goals werent aligned with those of the rhinoceros And it didnt work out so well for the rhinoceros because we were more intelligent right So I think its just so important that if we ever do build AGI before we unleash anything we have to make sure that it learns to understand our goals that it adopts our goals and that it retains those goals So the cool interesting problem there is us as human beings trying to formulate our values So you could think of the United States Constitution as a way that people sat down at the time a bunch of white men which is a good example I should say They formulated the goals for this country And a lot of people agree that those goals actually held up pretty well Thats an interesting formulation of values and failed miserably in other ways So for the value alignment problem and the solution to it we have to be able to put on paper or in a program human values How difficult do you think that is Very But its so important We really have to give it our best And its difficult for two separate reasons Theres the technical value alignment problem of figuring out just how to make machines understand our goals', 'figuring out just how to make machines understand our goals adopt them and retain them And then theres the separate part of it the philosophical part Whose values anyway And since its not like we have any great consensus on this planet on values what mechanism should we create then to aggregate and decide OK whats a good compromise That second discussion cant just be left to tech nerds like myself And if we refuse to talk about it and then AGI gets built whos going to be actually making the decision about whose values Its going to be a bunch of dudes in some tech company And are they necessarily so representative of all of humankind that we want to just entrust it to them Are they even uniquely qualified to speak to future human happiness just because theyre good at programming AI Id much rather have this be a really inclusive conversation But do you think its possible So you create a beautiful vision that includes the diversity cultural diversity and various perspectives on discussing rights freedoms human dignity But how hard is it to come to that consensus Do you think its certainly a really important thing that we should all try to do But do you think its feasible I think theres no better way to guarantee failure than to refuse to talk about it or refuse to try And I also think its a really bad strategy to say OK lets first have a discussion for a long time And then once we reach complete consensus then well try to load it into some machine No we shouldnt let perfect be the enemy of good Instead we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now Were not doing that even Look at anyone who builds this passenger aircraft wants it to never under any circumstances fly into a building or a mountain Yet the September  hijackers were able to do', 'or a mountain Yet the September  hijackers were able to do that And even more embarrassingly Andreas Lubitz this depressed Germanwings pilot when he flew his passenger jet into the Alps killing over people he just told the autopilot to do it He told the freaking computer to change the altitude to  meters And even though it had the GPS maps everything the computer was like OK So we should take those very basic values where the problem is not that we dont agree The problem is just weve been too lazy to try to put it into our machines and make sure that from now on airplanes will just which all have computers in them but will just refuse to do something like that Go into safe mode maybe lock the cockpit door go over to the nearest airport And theres so much other technology in our world as well now where its really becoming quite timely to put in some sort of very basic values like this Even in cars weve had enough vehicle terrorism attacks by now where people have driven trucks and vans into pedestrians that its not at all a crazy idea to just have that hardwired into the car Because yeah there are a lot of theres always going to be people who for some reason want to harm others but most of those people dont have the technical expertise to figure out how to work around something like that So if the car just wont do it it helps So lets start there So theres a lot of thats a great point So not chasing perfect Theres a lot of things that most of the world agrees on Yeah lets start there Lets start there And then once we start there well also get into the habit of having these kind of conversations about okay what else should we put in here and have these discussions This should be a gradual process then Great so but that also means describing these things and describing it to a machine So one thing we had a few conversations', 'it to a machine So one thing we had a few conversations with Stephen Wolfram Im not sure if youre familiar with Stephen Oh yeah I know him quite well So he is he works with a bunch of things but cellular automata these simple computable things these computation systems And he kind of mentioned that we probably have already within these systems already something thats AGI meaning like we just dont know it because we cant talk to it So if you give me this chance to try to at least form a question out of this is I think its an interesting idea to think that we can have intelligent systems but we dont know how to describe something to them and they cant communicate with us I know youre doing a little bit of work in explainable AI trying to get AI to explain itself So what are your thoughts of natural language processing or some kind of other communication How does the AI explain something to us How do we explain something to it to machines Or you think of it differently So there are two separate parts to your question there One of them has to do with communication which is super interesting Ill get to that in a sec The other is whether we already have AGI but we just havent noticed it there Right There I beg to differ I dont think theres anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better I think the day that happens when that happens we will very soon notice well probably notice even before because in a very very big way But for the second part though Wait can I ask sorry So because you have this beautiful way to formulating consciousness as information processing and you can think of intelligence as information processing and you can think of the entire universe as these', 'processing and you can think of the entire universe as these particles and these systems roaming around that have this information processing power You dont think there is something with the power to process information in the way that we human beings do thats out there that needs to be sort of connected to It seems a little bit philosophical perhaps but theres something compelling to the idea that the power is already there which the focus should be more on being able to communicate with it Well I agree that in a certain sense the hardware processing power is already out there because our universe itself can think of it as being a computer already right Its constantly computing what water waves how it devolved the water waves in the River Charles and how to move the air molecules around Seth Lloyd has pointed out my colleague here that you can even in a very rigorous way think of our entire universe as being a quantum computer Its pretty clear that our universe supports this amazing processing power because you can even within this physics computer that we live in right We can even build actual laptops and stuff so clearly the power is there Its just that most of the compute power that nature has its in my opinion kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking right So in a sense what life does what we are doing when we build computers is were rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave and lets do something cool here So the raw hardware power is there for sure but then even just computing whats going to happen for the next five seconds in this water bottle takes a ridiculous amount of compute if you do it on a human computer This water bottle', 'of compute if you do it on a human computer This water bottle just did it But that does not mean that this water bottle has AGI because AGI means it should also be able to like Ive written my book done this interview And I dont think its just communication problems I dont really think it can do it Although Buddhists say when they watch the water and that there is some beauty that theres some depth and beauty in nature that they can communicate with Communication is also very important though because I mean look part of my job is being a teacher And I know some very intelligent professors even who just have a bit of hard time communicating They come up with all these brilliant ideas but to communicate with somebody else you have to also be able to simulate their own mind Yes empathy Build well enough and understand model of their mind that you can say things that they will understand And thats quite difficult And thats why today its so frustrating if you have a computer that makes some cancer diagnosis and you ask it well why are you saying I should have this surgery And if it can only reply I was trained on five terabytes of data and this is my diagnosis boop boop beep beep It doesnt really instill a lot of confidence right So I think we have a lot of work to do on communication there So what kind of I think youre doing a little bit of work in explainable AI What do you think are the most promising avenues Is it mostly about sort of the Alexa problem of natural language processing of being able to actually use human interpretable methods of communication So being able to talk to a system and it talk back to you or is there some more fundamental problems to be solved I think its all of the above The natural language processing is obviously important but there are also more nerdy fundamental problems Like if you', 'there are also more nerdy fundamental problems Like if you take you play chess Of course Im Russian I have to You speak Russian Yes I speak Russian Excellent I didnt know When did you learn Russian I speak very bad Russian Im only an autodidact but I bought a book Teach Yourself Russian read a lot but it was very difficult Wow Thats why I speak so bad How many languages do you know Wow thats really impressive I dont know my wife has some calculation but my point was if you play chess have you looked at the AlphaZero games The actual games no Check it out some of them are just mind blowing really beautiful And if you ask how did it do that You go talk to Demis Hassabis I know others from DeepMind all theyll ultimately be able to give you is big tables of numbers matrices that define the neural network And you can stare at these tables of numbers till your face turn blue and youre not gonna understand much about why it made that move And even if you have natural language processing that can tell you in human language about oh five seven points two eight still not gonna really help So I think theres a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good equally intelligent but thats more understandable And I think thats really valuable because I think as we put machines in charge of ever more infrastructure in our world the power grid the trading on the stock market weapon systems and so on its absolutely crucial that we can trust these AIs to do all we want And trust really comes from understanding in a very fundamental way And thats why Im working on this because I think the more if were gonna have some hope of ensuring that machines have adopted our goals and that theyre gonna retain them that kind of trust I', 'goals and that theyre gonna retain them that kind of trust I think needs to be based on things you can actually understand preferably even improve theorems on Even with a self driving car right If someone just tells you its been trained on tons of data and it never crashed its less reassuring than if someone actually has a proof Maybe its a computer verified proof but still it says that under no circumstances is this car just gonna swerve into oncoming traffic And that kind of information helps to build trust and helps build the alignment of goals at least awareness that your goals your values are aligned And I think even in the very short term if you look at how you know today right This absolutely pathetic state of cybersecurity that we have where is it Three billion Yahoo accounts we cant pack almost every Americans credit card and so on Why is this happening Its ultimately happening because we have software that nobody fully understood how it worked Thats why the bugs hadnt been found right And I think AI can be used very effectively for offense for hacking but it can also be used for defense Hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them And its important So speaking of software that nobody understands how it works of course a bunch of people ask about your paper about your thoughts of why does deep and cheap learning work so well Thats the paper But what are your thoughts on deep learning These kind of simplified models of our own brains have been able to do some successful perception work pattern recognition work and now with AlphaZero and so on do some clever things What are your thoughts about the promise limitations of this piece Great I think there are a number of very important insights very', 'I think there are a number of very important insights very important lessons we can always draw from these kinds of successes One of them is when you look at the human brain you see its very complicated th of  neurons and there are all these different kinds of neurons and yada yada and theres been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence We can now I think quite convincingly answer that question of no its enough to have just one kind If you look under the hood of AlphaZero theres only one kind of neuron and its ridiculously simple mathematical thing So its just like in physics its not if you have a gas with waves in it its not the detailed nature of the molecule that matter its the collective behavior somehow Similarly its this higher level structure of the network that matters not that you have  kinds of neurons I think our brain is such a complicated mess because it wasnt evolved just to be intelligent it was involved to also be self assembling and self repairing right And evolutionarily attainable And so on and so on So I think its pretty my hunch is that were going to understand how to build AGI before we fully understand how our brains work just like we understood how to build flying machines long before we were able to build a mechanical bird Yeah thats right Youve given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight And even now after  years later did you see the Ted talk with this German mechanical bird I heard you mention it Check it out its amazing But even after that right we still dont fly in mechanical birds because it turned out the way we came up with was simpler and its better for our purposes And I think it might be the same', 'its better for our purposes And I think it might be the same there Thats one lesson And another lesson its more what our paper was about First as a physicist thought it was fascinating how theres a very close mathematical relationship actually between our artificial neural networks and a lot of things that weve studied for in physics go by nerdy names like the renormalization group equation and Hamiltonians and yada yada yada And when you look a little more closely at this you have at first I was like well theres something crazy here that doesnt make sense Because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures right that you can do that very very well now But if you think about it a little bit you convince yourself it must be impossible because if I have one megapixel even if each pixel is just black or white theres two to the power of  million possible images which is way more than there are atoms in our universe right so in order to and then for each one of those I have to assign a number which is the probability that its a dog So an arbitrary function of images is a list of more numbers than there are atoms in our universe So clearly I cant store that under the hood of my GPU or my computer yet somehow it works So what does that mean Well it means that out of all of the problems that you could try to solve with a neural network almost all of them are impossible to solve with a reasonably sized one But then what we showed in our paper was that the fraction the kind of problems the fraction of all the problems that you could possibly pose that we actually care about given the laws of physics is also an infinite testimony tiny little part And amazingly theyre basically the same part Yeah its almost like our world was created for I mean they kind of come', 'almost like our world was created for I mean they kind of come together Yeah well you could say maybe where the world was created for us but I have a more modest interpretation which is that the world was created for us but I have a more modest interpretation which is that instead evolution endowed us with neural networks precisely for that reason Because this particular architecture as opposed to the one in your laptop is very very well adapted to solving the kind of problems that nature kept presenting our ancestors with So it makes sense that why do we have a brain in the first place Its to be able to make predictions about the future and so on So if we had a sucky system which could never solve it we wouldnt have a world So this is I think a very beautiful fact Yeah We also realize that theres been earlier work on why deeper networks are good but we were able to show an additional cool fact there which is that even incredibly simple problems like suppose I give you a thousand numbers and ask you to multiply them together and you can write a few lines of code boom done trivial If you just try to do that with a neural network that has only one single hidden layer in it you can do it but youre going to need two to the power of a thousand neurons to multiply a thousand numbers which is again more neurons than there are atoms in our universe Thats fascinating But if you allow yourself to make it a deep network with many layers you only need  neurons Its perfectly feasible Thats really interesting Yeah So on another architecture type I mean you mentioned Schrodingers equation and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system In some Hollywood movies that I will not mention by name because I dont want to spoil them The way they get', 'by name because I dont want to spoil them The way they get AGI is building a quantum computer Because the word quantum sounds cool and so on Thats right First of all I think we dont need quantum computers to build AGI I suspect your brain is not a quantum computer in any profound sense So you dont even wrote a paper about that a lot many years ago I calculated the so called decoherence time how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment And its about  to the minus  seconds So as cool as it would be to have a quantum computer in my head I dont think that fast On the other hand there are very cool things you could do with quantum computers Or I think well be able to do soon when we get bigger ones That might actually help machine learning do even better than the brain So for example one this is just a moonshot but learning is very much same thing as search If youre trying to train a neural network to get really learned to do something really well you have some loss function you have a bunch of knobs you can turn represented by a bunch of numbers and youre trying to tweak them so that it becomes as good as possible at this thing So if you think of a landscape with some valley where each dimension of the landscape corresponds to some number you can change youre trying to find the minimum And its well known that if you have a very high dimensional landscape complicated things its super hard to find the minimum Quantum mechanics is amazingly good at this Like if I want to know whats the lowest energy state this water can possibly have incredibly hard to compute but nature will happily figure this out for you if you just cool it down make it very very cold If you put a ball somewhere itll roll down to its minimum And this happens metaphorically', 'roll down to its minimum And this happens metaphorically at the energy landscape too And quantum mechanics even uses some clever tricks which todays machine learning systems dont Like if youre trying to find the minimum and you get stuck in the little local minimum here in quantum mechanics you can actually tunnel through the barrier and get unstuck again Thats really interesting Yeah so it may be for example that well one day use quantum computers that help train neural networks better Thats really interesting Okay so as a component of kind of the learning process for example Yeah Let me ask sort of wrapping up here a little bit let me return to the questions of our human nature and love as I mentioned So do you think you mentioned sort of a helper robot but you could think of also personal robots Do you think the way we human beings fall in love and get connected to each other is possible to achieve in an AI system and human level AI intelligence system Do you think we would ever see that kind of connection Or you know in all this discussion about solving complex goals is this kind of human social connection do you think thats one of the goals on the peaks and valleys with the raising sea levels that well be able to achieve Or do you think thats something thats ultimately or at least in the short term relative to the other goals is not achievable I think its all possible And I mean in recent theres a very wide range of guesses as you know among AI researchers when were going to get AGI Some people you know like our friend Rodney Brooks says its going to be hundreds of years at least And then there are many others who think its going to happen much sooner And recent polls maybe half or so of AI researchers think were going to get AGI within decades So if that happens of course then I think these things are all', 'So if that happens of course then I think these things are all possible But in terms of whether it will happen I think we shouldnt spend so much time asking what do we think will happen in the future As if we are just some sort of pathetic your passive bystanders you know waiting for the future to happen to us Hey were the ones creating this future right So we should be proactive about it and ask ourselves what sort of future we would like to have happen Were going to make it like that Well what I prefer is just some sort of incredibly boring zombie like future where theres all these mechanical things happening and theres no passion no emotion no experience maybe even No I would of course much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience passion inspiration love you know If we can create a future where those things do happen where those things do exist you know I think ultimately its not our universe giving meaning to us its us giving meaning to our universe And if we build more advanced intelligence lets make sure we build it in such a way that meaning is part of it A lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases if they think through that happen are the ones that are not beneficial to humanity And so yeah so what are your thoughts Whats should people you know I really dont like people to be terrified Whats a way for people to think about it in a way we can solve it and we can make it better No I dont think panicking is going to help in any way Its not going to increase chances of things going well either Even if you are in a situation where there is a real threat does it help if everybody just freaks out No of course of course not I think yeah there are of course ways in which', 'of course not I think yeah there are of course ways in which things can go horribly wrong First of all its important when we think about this thing about the problems and risks to also remember how huge the upsides can be if we get it right right Everything we love about society and civilization is a product of intelligence So if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what were told is an incurable disease and things like this of course we should aspire to that So that can be a motivator I think reminding ourselves that the reason we try to solve problems is not just because were trying to avoid gloom but because were trying to do something great But then in terms of the risks I think the really important question is to ask what can we do today that will actually help make the outcome good right And dismissing the risk is not one of them I find it quite funny often when Im in discussion panels about these things how the people who work for companies always be like oh nothing to worry about nothing to worry about nothing to worry about And its only academics sometimes express concerns Thats not surprising at all if you think about it Right Upton Sinclair quipped right that its hard to make a man believe in something when his income depends on not believing in it And frankly we know a lot of these people in companies that theyre just as concerned as anyone else But if youre the CEO of a company thats not something you want to go on record saying when you have silly journalists who are gonna put a picture of a Terminator robot when they quote you So the issues are real And the way I think about what the issue is is basically the real choice we have is first of all are we gonna just dismiss the risks and say well lets just go ahead and build machines that can do', 'and say well lets just go ahead and build machines that can do everything we can do better and cheaper Lets just make ourselves obsolete as fast as possible What could possibly go wrong Thats one attitude The opposite attitude I think is to say heres this incredible potential lets think about what kind of future were really really excited about What are the shared goals that we can really aspire towards And then lets think really hard about how we can actually get there So start with dont start thinking about the risks start thinking about the goals And then when you do that then you can think about the obstacles you want to avoid I often get students coming in right here into my office for career advice I always ask them this very question where do you want to be in the future If all she can say is oh maybe Ill have cancer maybe Ill get run over by a truck Yeah focus on the obstacles instead of the goals Shes just going to end up a hypochondriac paranoid Whereas if she comes in and fire in her eyes and is like I want to be there And then we can talk about the obstacles and see how we can circumvent them Thats I think a much much healthier attitude And I feel its very challenging to come up with a vision for the future which we are unequivocally excited about Im not just talking now in the vague terms like yeah lets cure cancer fine Im talking about what kind of society do we want to create What do we want it to mean to be human in the age of AI in the age of AGI So if we can have this conversation broad inclusive conversation and gradually start converging towards some some future that with some direction at least that we want to steer towards right then well be much more motivated to constructively take on the obstacles And I think if I had if I had to if I try to wrap this up in a more succinct way I think we can all agree', 'to wrap this up in a more succinct way I think we can all agree already now that we should aspire to build AGI that doesnt overpower us but that empowers us And think of the many various ways that can do that whether thats from my side of the world of autonomous vehicles Im personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of So thats one example and certainly theres a lot of other types of robots and medicine and so on So focusing on those and then coming up with the obstacles coming up with the ways that that can go wrong and solving those one at a time And just because you can build an autonomous vehicle even if you could build one that would drive just fine without you maybe there are some things in life that we would actually want to do ourselves Thats right Right like for example if you think of our society as a whole there are some things that we find very meaningful to do And that doesnt mean we have to stop doing them just because machines can do them better Im not gonna stop playing tennis just the day someone builds a tennis robot and beat me People are still playing chess and even go Yeah and in the very near term even some people are advocating basic income replace jobs But if the government is gonna be willing to just hand out cash to people for doing nothing then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing right We get very tired of hearing politicians saying oh we cant afford hiring more teachers but were gonna maybe have basic income If we can have more serious research and thought into what gives meaning to our lives', 'research and thought into what gives meaning to our lives the jobs give so much more than income right Mm hmm And then think about in the future what are the roles that we wanna have people continually feeling empowered by machines And I think sort of I come from Russia from the Soviet Union And I think for a lot of people in the th century going to the moon going to space was an inspiring thing I feel like the universe of the mind so AI understanding creating intelligence is that for the st century So its really surprising And Ive heard you mention this Its really surprising to me both on the research funding side that its not funded as greatly as it could be but most importantly on the politician side that its not part of the public discourse except in the killer bots terminator kind of view that people are not yet I think perhaps excited by the possible positive future that we can build together So we should be because politicians usually just focus on the next election cycle right The single most important thing I feel we humans have learned in the entire history of science is they were the masters of underestimation We underestimated the size of our cosmos again and again realizing that everything we thought existed was just a small part of something grander right Planet solar system the galaxy clusters of galaxies The universe And we now know that the future has just so much more potential than our ancestors could ever have dreamt of This cosmos imagine if all of Earth was completely devoid of life except for Cambridge Massachusetts Wouldnt it be kind of lame if all we ever aspired to was to stay in Cambridge Massachusetts forever and then go extinct in one week even though Earth was gonna continue on for longer That sort of attitude I think we have now on the cosmic scale life can flourish on', 'I think we have now on the cosmic scale life can flourish on Earth not for four years but for billions of years I can even tell you about how to move it out of harms way when the sun gets too hot And then we have so much more resources out here which today maybe there are a lot of other planets with bacteria or cow like life on them but most of this all this opportunity seems as far as we can tell to be largely dead like the Sahara Desert And yet we have the opportunity to help life flourish around this for billions of years So lets quit squabbling about whether some little border should be drawn one mile to the left or right and look up into the skies and realize hey we can do such incredible things Yeah and thats I think why its really exciting that you and others are connected with some of the work Elon Musk is doing because hes literally going out into that space really exploring our universe and its wonderful That is exactly why Elon Musk is so misunderstood right Misconstrued him as some kind of pessimistic doomsayer The reason he cares so much about AI safety is because he more than almost anyone else appreciates these amazing opportunities that well squander if we wipe out here on Earth Were not just going to wipe out the next generation all generations and this incredible opportunity thats out there and that would really be a waste And AI for people who think that it would be better to do without technology let me just mention that if we dont improve our technology the question isnt whether humanity is going to go extinct The question is just whether were going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech right And if we want life to flourish throughout the cosmos AI is the key to it As I mentioned in a lot of detail in my', 'cosmos AI is the key to it As I mentioned in a lot of detail in my book right there even many of the most inspired sci fi writers I feel have totally underestimated the opportunities for space travel especially at the other galaxies because they werent thinking about the possibility of AGI which just makes it so much easier Right yeah So that goes to your view of AGI that enables our progress that enables a better life So thats a beautiful way to put it and then something to strive for So Max thank you so much Thank you for your time today Its been awesome Thank you so much Thanks Have a great day']] is not valid under any of the given schemas - 'input'\n"
     ]
    }
   ],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "index_name = \"shenyen-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "try:\n",
    "    # Initialize with small set of data - \n",
    "    p = Pinecone.from_texts(splits_all[0:1], \n",
    "                           embeddings, \n",
    "                           index_name=index_name, \n",
    "                           metadatas=metadatas_all[0:1])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# Update - \n",
    "# index_name = \"shenyen-gpt\"\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data in chunk to avoid data ingest errors\n",
    "chunk_size = 100\n",
    "last_chunk = 0\n",
    "num_chunks = math.ceil(len(splits_all) / chunk_size)\n",
    "for i in range(last_chunk,num_chunks):\n",
    "    \n",
    "    print(i)\n",
    "    start_time = time.time()\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, len(splits_all))\n",
    "    \n",
    "    # Extract the current chunk\n",
    "    current_splits = splits_all[start_idx:end_idx]\n",
    "    current_metadatas = metadatas_all[start_idx:end_idx]\n",
    "    \n",
    "    # Add the current chunk to the vector database\n",
    "    p.add_texts(texts = current_splits, metadatas=current_metadatas)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8. Read in VectorDB for testing` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "index_name = \"lex-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`9. Run VectorDBQAWithSourcesChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vectordb_sources_chain(llm,query,docstore):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = VectorDBQAWithSourcesChain.from_chain_type(llm, chain_type=\"stuff\", vectorstore=docstore)\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")\n",
    "\n",
    "llm = OpenAIChat(temperature=0)\n",
    "q = \"What does Eleazar Yukowski think about AI alignment?\"\n",
    "run_vectordb_sources_chain(llm,q,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
